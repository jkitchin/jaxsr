{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Level Constraint Enforcement in JAXSR\n",
    "\n",
    "JAXSR supports three levels of constraint enforcement for shape constraints\n",
    "(monotonicity, convexity, bounds, linear):\n",
    "\n",
    "| Level | Solver | Guarantee | Extra deps |\n",
    "|-------|--------|-----------|------------|\n",
    "| `\"penalty\"` | L-BFGS-B + penalty | Approximate | None |\n",
    "| `\"constrained\"` | scipy trust-constr | Solver tolerance (~1e-8) | None |\n",
    "| `\"exact\"` | cvxpy QP | Mathematical guarantee | `cvxpy` |\n",
    "\n",
    "This notebook compares all three on practical problems and demonstrates\n",
    "a CSTR reactor example with a mass-balance constraint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from jaxsr import BasisLibrary, Constraints, SymbolicRegressor\n",
    "from jaxsr.constraints import fit_constrained_ols\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions\n",
    "\n",
    "Utilities for timing fits, measuring constraint violations, and plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_time(Phi, y, X, constraints, basis_names, feature_names,\n",
    "                 library, selected_indices, enforcement, n_repeats=3):\n",
    "    \"\"\"Fit with the given enforcement level and return coeffs, mse, elapsed.\"\"\"\n",
    "    times = []\n",
    "    for _ in range(n_repeats):\n",
    "        t0 = time.perf_counter()\n",
    "        coeffs, mse = fit_constrained_ols(\n",
    "            Phi=Phi, y=y, constraints=constraints,\n",
    "            basis_names=basis_names, feature_names=feature_names,\n",
    "            X=X, basis_library=library, selected_indices=selected_indices,\n",
    "            enforcement=enforcement,\n",
    "        )\n",
    "        times.append(time.perf_counter() - t0)\n",
    "    return coeffs, mse, np.median(times)\n",
    "\n",
    "\n",
    "def monotonic_violations(y_pred):\n",
    "    \"\"\"Count and measure violations of non-decreasing monotonicity.\"\"\"\n",
    "    diffs = np.diff(np.asarray(y_pred))\n",
    "    violations = diffs[diffs < -1e-10]\n",
    "    return len(violations), float(np.min(diffs)) if len(diffs) > 0 else 0.0\n",
    "\n",
    "\n",
    "def convexity_violations(y_pred):\n",
    "    \"\"\"Count and measure violations of convexity (2nd differences >= 0).\"\"\"\n",
    "    sd = np.diff(np.asarray(y_pred), n=2)\n",
    "    violations = sd[sd < -1e-10]\n",
    "    return len(violations), float(np.min(sd)) if len(sd) > 0 else 0.0\n",
    "\n",
    "\n",
    "def bound_violations(y_pred, upper):\n",
    "    \"\"\"Count and measure violations of an upper bound.\"\"\"\n",
    "    y_np = np.asarray(y_pred)\n",
    "    excess = y_np - upper\n",
    "    violations = excess[excess > 1e-10]\n",
    "    return len(violations), float(np.max(excess))\n",
    "\n",
    "\n",
    "LEVELS = [\"penalty\", \"constrained\"]\n",
    "\n",
    "try:\n",
    "    import cvxpy  # noqa: F401\n",
    "    LEVELS.append(\"exact\")\n",
    "    print(\"cvxpy available — all three enforcement levels will be tested.\")\n",
    "except ImportError:\n",
    "    print(\"cvxpy not installed — 'exact' level will be skipped.\")\n",
    "    print(\"Install with:  pip install jaxsr[qp]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Monotonicity Constraint\n",
    "\n",
    "True model: $y = -x^2 + 3x$, which is **not** monotonically increasing over $[0, 3]$.\n",
    "We fit a polynomial and require the model to be monotonically increasing,\n",
    "forcing a compromise between data fidelity and the constraint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "X_mono = np.linspace(0, 3, 80).reshape(-1, 1)\n",
    "y_mono = -X_mono[:, 0] ** 2 + 3 * X_mono[:, 0]\n",
    "\n",
    "library_mono = (\n",
    "    BasisLibrary(n_features=1, feature_names=[\"x\"])\n",
    "    .add_constant()\n",
    "    .add_linear()\n",
    "    .add_polynomials(max_degree=3)\n",
    ")\n",
    "Phi_mono = library_mono.evaluate(jnp.array(X_mono))\n",
    "sel_mono = jnp.arange(len(library_mono.names))\n",
    "\n",
    "constraints_mono = Constraints().add_monotonic(\n",
    "    \"x\", direction=\"increasing\", hard=True\n",
    ")\n",
    "\n",
    "# Fit with each enforcement level\n",
    "results_mono = {}\n",
    "for level in LEVELS:\n",
    "    coeffs, mse, elapsed = fit_and_time(\n",
    "        Phi_mono, jnp.array(y_mono), jnp.array(X_mono),\n",
    "        constraints_mono, library_mono.names, [\"x\"],\n",
    "        library_mono, sel_mono, level,\n",
    "    )\n",
    "    y_pred = np.array(Phi_mono @ coeffs)\n",
    "    n_viol, worst = monotonic_violations(y_pred)\n",
    "    results_mono[level] = {\n",
    "        \"coeffs\": coeffs, \"mse\": mse, \"time\": elapsed,\n",
    "        \"y_pred\": y_pred, \"n_violations\": n_viol, \"worst_violation\": worst,\n",
    "    }\n",
    "\n",
    "# Summary table\n",
    "print(f\"{'Level':<14s} {'MSE':>10s} {'Violations':>11s} {'Worst diff':>11s} {'Time (ms)':>10s}\")\n",
    "print(\"-\" * 60)\n",
    "for level, r in results_mono.items():\n",
    "    print(\n",
    "        f\"{level:<14s} {r['mse']:10.6f} {r['n_violations']:11d}\"\n",
    "        f\" {r['worst_violation']:11.2e} {r['time']*1000:10.1f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(13, 5))\n",
    "\n",
    "# Left: fitted curves\n",
    "ax = axes[0]\n",
    "ax.plot(X_mono, y_mono, \"k--\", label=\"True (non-monotonic)\", linewidth=1.5)\n",
    "colors = {\"penalty\": \"#e74c3c\", \"constrained\": \"#2ecc71\", \"exact\": \"#3498db\"}\n",
    "for level, r in results_mono.items():\n",
    "    ax.plot(X_mono, r[\"y_pred\"], color=colors[level], label=f\"{level} (MSE={r['mse']:.4f})\")\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")\n",
    "ax.set_title(\"Monotonicity Constraint: Fitted Curves\")\n",
    "ax.legend(fontsize=9)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Right: first differences (should all be >= 0)\n",
    "ax = axes[1]\n",
    "x_diff = X_mono[1:, 0]\n",
    "for level, r in results_mono.items():\n",
    "    diffs = np.diff(r[\"y_pred\"])\n",
    "    ax.plot(x_diff, diffs, color=colors[level], label=level)\n",
    "ax.axhline(0, color=\"k\", linestyle=\"--\", linewidth=0.8)\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"dy/dx (finite diff)\")\n",
    "ax.set_title(\"First Differences (should be >= 0)\")\n",
    "ax.legend(fontsize=9)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Convexity Constraint\n",
    "\n",
    "True model: $y = -x^2$ (concave). We fit with a **convexity** constraint, so the\n",
    "solver must find the best convex approximation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cvx = np.linspace(-2, 2, 80).reshape(-1, 1)\n",
    "y_cvx = -X_cvx[:, 0] ** 2 + 0.1 * np.random.randn(80)\n",
    "\n",
    "library_cvx = (\n",
    "    BasisLibrary(n_features=1, feature_names=[\"x\"])\n",
    "    .add_constant()\n",
    "    .add_linear()\n",
    "    .add_polynomials(max_degree=3)\n",
    ")\n",
    "Phi_cvx = library_cvx.evaluate(jnp.array(X_cvx))\n",
    "sel_cvx = jnp.arange(len(library_cvx.names))\n",
    "\n",
    "constraints_cvx = Constraints().add_convex(\"x\", hard=True)\n",
    "\n",
    "results_cvx = {}\n",
    "for level in LEVELS:\n",
    "    coeffs, mse, elapsed = fit_and_time(\n",
    "        Phi_cvx, jnp.array(y_cvx), jnp.array(X_cvx),\n",
    "        constraints_cvx, library_cvx.names, [\"x\"],\n",
    "        library_cvx, sel_cvx, level,\n",
    "    )\n",
    "    y_pred = np.array(Phi_cvx @ coeffs)\n",
    "    n_viol, worst = convexity_violations(y_pred)\n",
    "    results_cvx[level] = {\n",
    "        \"coeffs\": coeffs, \"mse\": mse, \"time\": elapsed,\n",
    "        \"y_pred\": y_pred, \"n_violations\": n_viol, \"worst_violation\": worst,\n",
    "    }\n",
    "\n",
    "print(f\"{'Level':<14s} {'MSE':>10s} {'Violations':>11s} {'Worst 2nd diff':>15s} {'Time (ms)':>10s}\")\n",
    "print(\"-\" * 65)\n",
    "for level, r in results_cvx.items():\n",
    "    print(\n",
    "        f\"{level:<14s} {r['mse']:10.6f} {r['n_violations']:11d}\"\n",
    "        f\" {r['worst_violation']:15.2e} {r['time']*1000:10.1f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(13, 5))\n",
    "\n",
    "ax = axes[0]\n",
    "ax.scatter(X_cvx, y_cvx, s=12, alpha=0.5, color=\"gray\", label=\"Data (concave)\")\n",
    "for level, r in results_cvx.items():\n",
    "    ax.plot(X_cvx, r[\"y_pred\"], color=colors[level], label=f\"{level} (MSE={r['mse']:.4f})\")\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")\n",
    "ax.set_title(\"Convexity Constraint: Fitted Curves\")\n",
    "ax.legend(fontsize=9)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "ax = axes[1]\n",
    "x_sd = X_cvx[1:-1, 0]\n",
    "for level, r in results_cvx.items():\n",
    "    sd = np.diff(r[\"y_pred\"], n=2)\n",
    "    ax.plot(x_sd, sd, color=colors[level], label=level)\n",
    "ax.axhline(0, color=\"k\", linestyle=\"--\", linewidth=0.8)\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"d²y/dx² (finite diff)\")\n",
    "ax.set_title(\"Second Differences (should be >= 0)\")\n",
    "ax.legend(fontsize=9)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Output Bounds Constraint\n",
    "\n",
    "True model: $y = 2x + 1$ over $x \\in [0, 5]$, giving $y \\in [1, 11]$.\n",
    "We impose a hard upper bound $y \\le 8$, which the true model violates for $x > 3.5$.\n",
    "The solver must find the best fit that respects the bound at the training points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bnd = np.linspace(0, 5, 80).reshape(-1, 1)\n",
    "y_bnd = 2 * X_bnd[:, 0] + 1 + 0.2 * np.random.randn(80)\n",
    "UPPER = 8.0\n",
    "\n",
    "library_bnd = (\n",
    "    BasisLibrary(n_features=1, feature_names=[\"x\"])\n",
    "    .add_constant()\n",
    "    .add_linear()\n",
    "    .add_polynomials(max_degree=2)\n",
    ")\n",
    "Phi_bnd = library_bnd.evaluate(jnp.array(X_bnd))\n",
    "sel_bnd = jnp.arange(len(library_bnd.names))\n",
    "\n",
    "constraints_bnd = Constraints().add_bounds(\"y\", upper=UPPER, hard=True)\n",
    "\n",
    "results_bnd = {}\n",
    "for level in LEVELS:\n",
    "    coeffs, mse, elapsed = fit_and_time(\n",
    "        Phi_bnd, jnp.array(y_bnd), jnp.array(X_bnd),\n",
    "        constraints_bnd, library_bnd.names, [\"x\"],\n",
    "        library_bnd, sel_bnd, level,\n",
    "    )\n",
    "    y_pred = np.array(Phi_bnd @ coeffs)\n",
    "    n_viol, worst = bound_violations(y_pred, UPPER)\n",
    "    results_bnd[level] = {\n",
    "        \"coeffs\": coeffs, \"mse\": mse, \"time\": elapsed,\n",
    "        \"y_pred\": y_pred, \"n_violations\": n_viol, \"worst_violation\": worst,\n",
    "    }\n",
    "\n",
    "print(f\"{'Level':<14s} {'MSE':>10s} {'Violations':>11s} {'Max excess':>11s} {'Time (ms)':>10s}\")\n",
    "print(\"-\" * 60)\n",
    "for level, r in results_bnd.items():\n",
    "    print(\n",
    "        f\"{level:<14s} {r['mse']:10.6f} {r['n_violations']:11d}\"\n",
    "        f\" {r['worst_violation']:11.2e} {r['time']*1000:10.1f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(13, 5))\n",
    "\n",
    "ax = axes[0]\n",
    "ax.scatter(X_bnd, y_bnd, s=12, alpha=0.5, color=\"gray\", label=\"Data\")\n",
    "ax.axhline(UPPER, color=\"k\", linestyle=\":\", linewidth=1.2, label=f\"Upper bound = {UPPER}\")\n",
    "for level, r in results_bnd.items():\n",
    "    ax.plot(X_bnd, r[\"y_pred\"], color=colors[level], label=f\"{level} (MSE={r['mse']:.4f})\")\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")\n",
    "ax.set_title(\"Output Bound Constraint: Fitted Curves\")\n",
    "ax.legend(fontsize=9)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Right: residuals\n",
    "ax = axes[1]\n",
    "for level, r in results_bnd.items():\n",
    "    resid = y_bnd - r[\"y_pred\"]\n",
    "    ax.scatter(r[\"y_pred\"], resid, s=15, alpha=0.5, color=colors[level], label=level)\n",
    "ax.axhline(0, color=\"k\", linestyle=\"--\", linewidth=0.8)\n",
    "ax.set_xlabel(\"Predicted\")\n",
    "ax.set_ylabel(\"Residual\")\n",
    "ax.set_title(\"Residuals by Enforcement Level\")\n",
    "ax.legend(fontsize=9)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Summary of Enforcement Levels\n",
    "\n",
    "Collect all results into a single comparison table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{'Problem':<16s} {'Level':<14s} {'MSE':>10s} {'Violations':>11s} {'Time (ms)':>10s}\")\n",
    "print(\"=\" * 65)\n",
    "for label, res in [(\"Monotonicity\", results_mono), (\"Convexity\", results_cvx), (\"Upper Bound\", results_bnd)]:\n",
    "    for level, r in res.items():\n",
    "        print(\n",
    "            f\"{label:<16s} {level:<14s} {r['mse']:10.6f}\"\n",
    "            f\" {r['n_violations']:11d} {r['time']*1000:10.1f}\"\n",
    "        )\n",
    "    print(\"-\" * 65)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key observations:**\n",
    "\n",
    "- **`penalty`**: Fastest, but may have small residual violations.\n",
    "- **`constrained`**: Slightly slower, violations driven to solver tolerance.\n",
    "- **`exact`** (if available): Violations at machine precision, but requires `cvxpy`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Using `SymbolicRegressor` with Enforcement Levels\n",
    "\n",
    "The `constraint_enforcement` parameter on `SymbolicRegressor` passes through\n",
    "to the internal fitting routine. Here we demonstrate the full pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reaction rate: r = k * C^0.5, must be non-negative and increasing in C\n",
    "np.random.seed(123)\n",
    "C = np.random.uniform(0.1, 3.0, 100).reshape(-1, 1)\n",
    "rate = 2.0 * C[:, 0] ** 0.5 + 0.05 * np.random.randn(100)\n",
    "\n",
    "library_rate = (\n",
    "    BasisLibrary(n_features=1, feature_names=[\"C\"])\n",
    "    .add_constant()\n",
    "    .add_linear()\n",
    "    .add_polynomials(max_degree=2)\n",
    "    .add_transcendental([\"sqrt\", \"log\"])\n",
    ")\n",
    "\n",
    "constraints_rate = (\n",
    "    Constraints()\n",
    "    .add_bounds(\"y\", lower=0, hard=True)\n",
    "    .add_monotonic(\"C\", direction=\"increasing\", hard=True)\n",
    ")\n",
    "\n",
    "for level in LEVELS:\n",
    "    t0 = time.perf_counter()\n",
    "    model = SymbolicRegressor(\n",
    "        basis_library=library_rate,\n",
    "        max_terms=3,\n",
    "        constraints=constraints_rate,\n",
    "        constraint_enforcement=level,\n",
    "    )\n",
    "    model.fit(C, rate)\n",
    "    elapsed = time.perf_counter() - t0\n",
    "\n",
    "    y_pred = np.array(model.predict(C))\n",
    "    n_neg = int(np.sum(y_pred < -1e-10))\n",
    "    C_sorted = np.sort(C[:, 0])\n",
    "    y_sorted = np.array(model.predict(C_sorted.reshape(-1, 1)))\n",
    "    n_mono, _ = monotonic_violations(y_sorted)\n",
    "\n",
    "    print(f\"[{level:<12s}]  expr = {model.expression_}\")\n",
    "    print(f\"{'':14s}  R² = {model.score(C, rate):.6f}  \"\n",
    "          f\"neg preds = {n_neg}  mono violations = {n_mono}  \"\n",
    "          f\"time = {elapsed*1000:.0f} ms\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. CSTR Reactor: Mass-Balance Constraint $x_A + x_B = 1$\n",
    "\n",
    "### Problem setup\n",
    "\n",
    "Consider a CSTR with irreversible reaction $A \\to B$.  The mole fractions\n",
    "$x_A$ and $x_B$ are measured as functions of temperature $T$ and space time\n",
    "$\\tau$.  By mass balance, $x_A + x_B = 1$ exactly, but each measurement is\n",
    "independently noisy so the measured values do not sum to 1.\n",
    "\n",
    "We fit **separate** symbolic regression models for $x_A(T, \\tau)$ and\n",
    "$x_B(T, \\tau)$, then use a **linear constraint on the combined coefficient\n",
    "vector** to enforce the mass balance across both models simultaneously.\n",
    "\n",
    "### True model\n",
    "\n",
    "$$\n",
    "x_A = \\frac{1}{1 + k(T)\\,\\tau}, \\qquad x_B = 1 - x_A\n",
    "$$\n",
    "\n",
    "where $k(T) = 0.5\\,e^{0.05\\,(T - 300)}$ is an Arrhenius-like rate constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate CSTR data\n",
    "np.random.seed(42)\n",
    "n_obs = 120\n",
    "T = np.random.uniform(280, 350, n_obs)   # temperature [K]\n",
    "tau = np.random.uniform(0.5, 5.0, n_obs)  # space time [min]\n",
    "\n",
    "k_true = 0.5 * np.exp(0.05 * (T - 300))\n",
    "xA_true = 1.0 / (1.0 + k_true * tau)\n",
    "xB_true = 1.0 - xA_true\n",
    "\n",
    "# Add independent measurement noise\n",
    "sigma_noise = 0.02\n",
    "xA_obs = xA_true + sigma_noise * np.random.randn(n_obs)\n",
    "xB_obs = xB_true + sigma_noise * np.random.randn(n_obs)\n",
    "\n",
    "print(f\"Mass-balance error in noisy data: \"\n",
    "      f\"mean|xA+xB-1| = {np.mean(np.abs(xA_obs + xB_obs - 1)):.4f}\")\n",
    "print(f\"Max |xA+xB-1| = {np.max(np.abs(xA_obs + xB_obs - 1)):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(16, 4.5))\n",
    "\n",
    "sc = axes[0].scatter(T, tau, c=xA_obs, cmap=\"RdYlGn\", s=20, edgecolors=\"white\", linewidth=0.3)\n",
    "axes[0].set_xlabel(\"Temperature [K]\")\n",
    "axes[0].set_ylabel(\"Space time [min]\")\n",
    "axes[0].set_title(\"$x_A$ (observed)\")\n",
    "plt.colorbar(sc, ax=axes[0])\n",
    "\n",
    "sc = axes[1].scatter(T, tau, c=xB_obs, cmap=\"RdYlGn\", s=20, edgecolors=\"white\", linewidth=0.3)\n",
    "axes[1].set_xlabel(\"Temperature [K]\")\n",
    "axes[1].set_ylabel(\"Space time [min]\")\n",
    "axes[1].set_title(\"$x_B$ (observed)\")\n",
    "plt.colorbar(sc, ax=axes[1])\n",
    "\n",
    "axes[2].hist(xA_obs + xB_obs - 1, bins=25, color=\"steelblue\", edgecolor=\"white\")\n",
    "axes[2].axvline(0, color=\"r\", linestyle=\"--\")\n",
    "axes[2].set_xlabel(\"$x_A + x_B - 1$\")\n",
    "axes[2].set_ylabel(\"Count\")\n",
    "axes[2].set_title(\"Mass-balance error (noisy data)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Strategy: joint basis matrix with coefficient-level constraints\n\nTo enforce $x_A + x_B = 1$ as a linear constraint on coefficients, we\nconstruct a **joint** design matrix by stacking the $x_A$ and $x_B$ basis\nmatrices block-diagonally:\n\n$$\n\\Phi_{\\text{joint}} = \\begin{pmatrix} \\Phi & 0 \\\\ 0 & \\Phi \\end{pmatrix}, \\qquad\n\\mathbf{c} = \\begin{pmatrix} \\mathbf{c}_A \\\\ \\mathbf{c}_B \\end{pmatrix}, \\qquad\n\\mathbf{y} = \\begin{pmatrix} x_A \\\\ x_B \\end{pmatrix}\n$$\n\nThe mass-balance constraint $\\hat{x}_A + \\hat{x}_B = 1$ for all inputs requires\n$\\Phi\\,(\\mathbf{c}_A + \\mathbf{c}_B) = \\mathbf{1}$. Since the first basis function\nis the constant \"1\", this is equivalent to the **coefficient-level** constraints:\n\n- $c_A^{(0)} + c_B^{(0)} = 1$ (constant terms sum to 1)\n- $c_A^{(j)} + c_B^{(j)} = 0$ for $j = 1, \\ldots, p-1$ (other terms cancel)\n\nThis gives just $p$ equality constraints on $2p$ coefficients — much more\nefficient than constraining at each observation."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build shared basis library (same features for xA and xB)\n",
    "X_cstr = np.column_stack([T, tau])\n",
    "\n",
    "library_cstr = (\n",
    "    BasisLibrary(n_features=2, feature_names=[\"T\", \"tau\"])\n",
    "    .add_constant()\n",
    "    .add_linear()\n",
    "    .add_polynomials(max_degree=2)\n",
    "    .add_interactions()\n",
    ")\n",
    "\n",
    "Phi_single = np.array(library_cstr.evaluate(jnp.array(X_cstr)))\n",
    "n_basis = Phi_single.shape[1]\n",
    "basis_names_single = library_cstr.names\n",
    "\n",
    "print(f\"Basis functions ({n_basis}): {basis_names_single}\")\n",
    "\n",
    "# Build block-diagonal joint design matrix\n",
    "Phi_joint = np.zeros((2 * n_obs, 2 * n_basis))\n",
    "Phi_joint[:n_obs, :n_basis] = Phi_single       # xA block\n",
    "Phi_joint[n_obs:, n_basis:] = Phi_single        # xB block\n",
    "\n",
    "y_joint = np.concatenate([xA_obs, xB_obs])\n",
    "\n",
    "# Joint basis names\n",
    "basis_names_joint = (\n",
    "    [f\"A:{n}\" for n in basis_names_single]\n",
    "    + [f\"B:{n}\" for n in basis_names_single]\n",
    ")\n",
    "\n",
    "print(f\"Joint system: {Phi_joint.shape[0]} obs x {Phi_joint.shape[1]} coefficients\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coefficient-level mass-balance constraints:\n",
    "#   c_A[0] + c_B[0] = 1      (constant terms sum to 1)\n",
    "#   c_A[j] + c_B[j] = 0      (all other terms cancel)\n",
    "#\n",
    "# In the joint coefficient vector c = [c_A; c_B] of length 2*n_basis,\n",
    "# each row of A selects a pair: A[j, j] = 1, A[j, n_basis+j] = 1.\n",
    "# Encode equality as two inequalities: A @ c <= b AND -A @ c <= -b.\n",
    "\n",
    "A_eq = np.zeros((n_basis, 2 * n_basis))\n",
    "for j in range(n_basis):\n",
    "    A_eq[j, j] = 1.0            # c_A[j]\n",
    "    A_eq[j, n_basis + j] = 1.0  # c_B[j]\n",
    "\n",
    "b_eq = np.zeros(n_basis)\n",
    "b_eq[0] = 1.0  # constant term sums to 1\n",
    "\n",
    "# Stack as two-sided inequality for add_linear_constraint (A @ c <= b)\n",
    "A_ineq = np.vstack([A_eq, -A_eq])\n",
    "b_ineq = np.concatenate([b_eq, -b_eq])\n",
    "\n",
    "print(f\"Coefficient-level constraint: {A_eq.shape[0]} equalities on {2*n_basis} coefficients\")\n",
    "print(f\"Encoded as {A_ineq.shape[0]} inequality rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit without constraint (baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unconstrained OLS baseline\n",
    "coeffs_ols, _, _, _ = np.linalg.lstsq(Phi_joint, y_joint, rcond=None)\n",
    "y_pred_ols = Phi_joint @ coeffs_ols\n",
    "xA_pred_ols = y_pred_ols[:n_obs]\n",
    "xB_pred_ols = y_pred_ols[n_obs:]\n",
    "mse_ols = float(np.mean((y_joint - y_pred_ols) ** 2))\n",
    "mb_error_ols = np.abs(xA_pred_ols + xB_pred_ols - 1)\n",
    "\n",
    "print(f\"Unconstrained OLS: MSE = {mse_ols:.6f}\")\n",
    "print(f\"  mean|xA+xB-1| = {np.mean(mb_error_ols):.6f}\")\n",
    "print(f\"  max |xA+xB-1| = {np.max(mb_error_ols):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit with mass-balance constraint at each enforcement level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_cstr = {}\n",
    "\n",
    "for level in LEVELS:\n",
    "    constraints_cstr = Constraints().add_linear_constraint(\n",
    "        A_ineq, b_ineq, hard=True\n",
    "    )\n",
    "\n",
    "    t0 = time.perf_counter()\n",
    "    coeffs, mse = fit_constrained_ols(\n",
    "        Phi=jnp.array(Phi_joint),\n",
    "        y=jnp.array(y_joint),\n",
    "        constraints=constraints_cstr,\n",
    "        basis_names=basis_names_joint,\n",
    "        feature_names=[\"T\", \"tau\"],\n",
    "        X=jnp.array(X_cstr),\n",
    "        enforcement=level,\n",
    "        max_iter=200,\n",
    "    )\n",
    "    elapsed = time.perf_counter() - t0\n",
    "\n",
    "    y_pred = np.array(jnp.array(Phi_joint) @ coeffs)\n",
    "    xA_pred = y_pred[:n_obs]\n",
    "    xB_pred = y_pred[n_obs:]\n",
    "    mb_error = np.abs(xA_pred + xB_pred - 1)\n",
    "\n",
    "    results_cstr[level] = {\n",
    "        \"coeffs\": coeffs, \"mse\": mse, \"time\": elapsed,\n",
    "        \"xA_pred\": xA_pred, \"xB_pred\": xB_pred,\n",
    "        \"mb_mean\": float(np.mean(mb_error)),\n",
    "        \"mb_max\": float(np.max(mb_error)),\n",
    "    }\n",
    "\n",
    "print(f\"{'Level':<14s} {'MSE':>10s} {'mean|err|':>10s} {'max|err|':>10s} {'Time (ms)':>10s}\")\n",
    "print(\"=\" * 58)\n",
    "print(f\"{'unconstrained':<14s} {mse_ols:10.6f} {np.mean(mb_error_ols):10.6f}\"\n",
    "      f\" {np.max(mb_error_ols):10.6f} {'--':>10s}\")\n",
    "for level, r in results_cstr.items():\n",
    "    print(\n",
    "        f\"{level:<14s} {r['mse']:10.6f} {r['mb_mean']:10.2e}\"\n",
    "        f\" {r['mb_max']:10.2e} {r['time']*1000:10.1f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(13, 10))\n",
    "\n",
    "# Top-left: xA parity\n",
    "ax = axes[0, 0]\n",
    "ax.scatter(xA_true, xA_pred_ols, s=12, alpha=0.4, color=\"gray\", label=\"Unconstrained\")\n",
    "for level, r in results_cstr.items():\n",
    "    ax.scatter(xA_true, r[\"xA_pred\"], s=12, alpha=0.5, color=colors[level], label=level)\n",
    "lims = [0, 1]\n",
    "ax.plot(lims, lims, \"k--\", linewidth=0.8)\n",
    "ax.set_xlabel(\"$x_A$ (true)\")\n",
    "ax.set_ylabel(\"$x_A$ (predicted)\")\n",
    "ax.set_title(\"$x_A$ Parity\")\n",
    "ax.legend(fontsize=8)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Top-right: xB parity\n",
    "ax = axes[0, 1]\n",
    "ax.scatter(xB_true, xB_pred_ols, s=12, alpha=0.4, color=\"gray\", label=\"Unconstrained\")\n",
    "for level, r in results_cstr.items():\n",
    "    ax.scatter(xB_true, r[\"xB_pred\"], s=12, alpha=0.5, color=colors[level], label=level)\n",
    "ax.plot(lims, lims, \"k--\", linewidth=0.8)\n",
    "ax.set_xlabel(\"$x_B$ (true)\")\n",
    "ax.set_ylabel(\"$x_B$ (predicted)\")\n",
    "ax.set_title(\"$x_B$ Parity\")\n",
    "ax.legend(fontsize=8)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Bottom-left: mass-balance error histogram\n",
    "ax = axes[1, 0]\n",
    "ax.hist(mb_error_ols, bins=25, alpha=0.4, color=\"gray\", label=\"Unconstrained\")\n",
    "for level, r in results_cstr.items():\n",
    "    mb_err = np.abs(r[\"xA_pred\"] + r[\"xB_pred\"] - 1)\n",
    "    ax.hist(mb_err, bins=25, alpha=0.5, color=colors[level], label=level)\n",
    "ax.set_xlabel(\"$|x_A + x_B - 1|$\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "ax.set_title(\"Mass-Balance Error Distribution\")\n",
    "ax.legend(fontsize=8)\n",
    "ax.set_yscale(\"log\")\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Bottom-right: mass-balance error vs observation index\n",
    "ax = axes[1, 1]\n",
    "ax.plot(mb_error_ols, \"o\", markersize=3, alpha=0.4, color=\"gray\", label=\"Unconstrained\")\n",
    "for level, r in results_cstr.items():\n",
    "    mb_err = np.abs(r[\"xA_pred\"] + r[\"xB_pred\"] - 1)\n",
    "    ax.plot(mb_err, \"o\", markersize=3, alpha=0.6, color=colors[level], label=level)\n",
    "ax.set_xlabel(\"Observation index\")\n",
    "ax.set_ylabel(\"$|x_A + x_B - 1|$\")\n",
    "ax.set_title(\"Mass-Balance Error per Observation\")\n",
    "ax.legend(fontsize=8)\n",
    "ax.set_yscale(\"log\")\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitted coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show coefficients for one representative level\n",
    "best_level = \"constrained\" if \"constrained\" in results_cstr else \"penalty\"\n",
    "coeffs_best = np.array(results_cstr[best_level][\"coeffs\"])\n",
    "\n",
    "print(f\"Fitted coefficients ({best_level} enforcement):\")\n",
    "print(f\"{'Basis':>20s}  {'Coeff (xA)':>12s}  {'Coeff (xB)':>12s}  {'Sum':>10s}\")\n",
    "print(\"-\" * 60)\n",
    "for i, name in enumerate(basis_names_single):\n",
    "    cA = coeffs_best[i]\n",
    "    cB = coeffs_best[n_basis + i]\n",
    "    print(f\"{name:>20s}  {cA:12.6f}  {cB:12.6f}  {cA+cB:10.6f}\")\n",
    "\n",
    "print()\n",
    "print(\"Note: for the constant term, cA + cB should equal 1.\")\n",
    "print(\"For all other terms, cA + cB should equal 0.\")\n",
    "print(\"(This is how Phi @ (cA + cB) = 1 works out when the constant column is all-ones.)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify constraint satisfaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mass-balance constraint satisfaction:\")\n",
    "print(f\"{'Level':<14s} {'mean|xA+xB-1|':>15s} {'max|xA+xB-1|':>15s} {'Satisfied?':>12s}\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'unconstrained':<14s} {np.mean(mb_error_ols):15.2e} {np.max(mb_error_ols):15.2e} {'No':>12s}\")\n",
    "for level, r in results_cstr.items():\n",
    "    sat = \"Yes\" if r[\"mb_max\"] < 1e-4 else \"Approx\"\n",
    "    print(f\"{level:<14s} {r['mb_mean']:15.2e} {r['mb_max']:15.2e} {sat:>12s}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Soft vs Hard Constraints\n",
    "\n",
    "The `hard` flag on each constraint interacts with the enforcement level:\n",
    "\n",
    "- **`hard=False`** constraints are always treated as **soft penalties**, regardless\n",
    "  of the enforcement level.\n",
    "- **`hard=True`** constraints get the full enforcement mechanism for the chosen level.\n",
    "\n",
    "Here we demonstrate with the monotonicity example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare hard vs soft monotonicity at each level\n",
    "print(f\"{'hard':>5s} {'Level':<14s} {'MSE':>10s} {'Violations':>11s} {'Worst diff':>12s}\")\n",
    "print(\"=\" * 56)\n",
    "\n",
    "for hard_flag in [True, False]:\n",
    "    constraints_hs = Constraints().add_monotonic(\n",
    "        \"x\", direction=\"increasing\", hard=hard_flag, weight=10.0\n",
    "    )\n",
    "    for level in LEVELS:\n",
    "        coeffs, mse = fit_constrained_ols(\n",
    "            Phi=Phi_mono, y=jnp.array(y_mono), constraints=constraints_hs,\n",
    "            basis_names=library_mono.names, feature_names=[\"x\"],\n",
    "            X=jnp.array(X_mono), basis_library=library_mono,\n",
    "            selected_indices=sel_mono, enforcement=level,\n",
    "            penalty_weight=10.0,\n",
    "        )\n",
    "        y_pred = np.array(Phi_mono @ coeffs)\n",
    "        n_viol, worst = monotonic_violations(y_pred)\n",
    "        print(\n",
    "            f\"{str(hard_flag):>5s} {level:<14s} {mse:10.6f}\"\n",
    "            f\" {n_viol:11d} {worst:12.2e}\"\n",
    "        )\n",
    "    print(\"-\" * 56)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `hard=False`, the constraint is always a soft penalty regardless of enforcement level,\n",
    "so all three levels produce similar results. With `hard=True`, the `constrained` and `exact`\n",
    "levels provide stronger satisfaction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "| Scenario | Recommended Level |\n",
    "|----------|------------------|\n",
    "| Quick exploration, soft guidance | `\"penalty\"` |\n",
    "| Safety-critical bounds, physical laws | `\"constrained\"` |\n",
    "| Publication-quality, exact guarantees | `\"exact\"` (requires `cvxpy`) |\n",
    "\n",
    "**Key points:**\n",
    "\n",
    "1. `\"penalty\"` is the fastest but may leave small residual violations.\n",
    "2. `\"constrained\"` (trust-constr) provides solver-level guarantees with no extra dependencies.\n",
    "3. `\"exact\"` (cvxpy QP) gives mathematical guarantees but requires `cvxpy` and does not support\n",
    "   nonlinear (CUSTOM) hard constraints.\n",
    "4. Soft constraints (`hard=False`) behave identically across all levels.\n",
    "5. The CSTR mass-balance example shows how linear equality constraints can enforce\n",
    "   physical conservation laws across multiple correlated outputs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}