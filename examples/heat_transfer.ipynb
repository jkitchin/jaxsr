{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eafb607c",
   "metadata": {},
   "source": [
    "# Heat Transfer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068d5707",
   "metadata": {},
   "source": [
    "Heat Transfer Example for JAXSR.\n",
    "\n",
    "Demonstrates discovering heat transfer correlations from data, including:\n",
    "- Nusselt number correlations\n",
    "- Natural convection\n",
    "- Forced convection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddc74687",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T22:35:24.236362Z",
     "iopub.status.busy": "2026-02-10T22:35:24.236264Z",
     "iopub.status.idle": "2026-02-10T22:35:24.724071Z",
     "shell.execute_reply": "2026-02-10T22:35:24.723640Z"
    }
   },
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "from jaxsr import BasisLibrary, Constraints, SymbolicRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cc32cd",
   "metadata": {},
   "source": [
    "## Discover Dittus-Boelter correlation for turbulent forced convection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1080159",
   "metadata": {},
   "source": [
    "**True model (Dittus\u2013Boelter):**\n",
    "\n",
    "$$\\mathrm{Nu} = 0.023\\,\\mathrm{Re}^{0.8}\\,\\mathrm{Pr}^{0.4}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb443081",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T22:35:24.725529Z",
     "iopub.status.busy": "2026-02-10T22:35:24.725432Z",
     "iopub.status.idle": "2026-02-10T22:35:26.371831Z",
     "shell.execute_reply": "2026-02-10T22:35:26.371416Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "n_samples = 100\n",
    "\n",
    "# Reynolds and Prandtl number ranges for turbulent flow\n",
    "Re = np.random.uniform(10000, 100000, n_samples)\n",
    "Pr = np.random.uniform(0.7, 100, n_samples)\n",
    "\n",
    "# Dittus-Boelter correlation\n",
    "Nu_true = 0.023 * Re**0.8 * Pr**0.4\n",
    "Nu = Nu_true * (1 + np.random.randn(n_samples) * 0.05)\n",
    "\n",
    "# Work in log space for power law discovery\n",
    "log_Re = np.log(Re)\n",
    "log_Pr = np.log(Pr)\n",
    "log_Nu = np.log(Nu)\n",
    "\n",
    "X = jnp.column_stack([log_Re, log_Pr])\n",
    "y = jnp.array(log_Nu)\n",
    "\n",
    "print(\"\\nTrue model: Nu = 0.023 * Re^0.8 * Pr^0.4\")\n",
    "print(f\"Log form: ln(Nu) = {np.log(0.023):.3f} + 0.8*ln(Re) + 0.4*ln(Pr)\")\n",
    "\n",
    "library = (\n",
    "    BasisLibrary(n_features=2, feature_names=[\"ln_Re\", \"ln_Pr\"])\n",
    "    .add_constant()\n",
    "    .add_linear()\n",
    "    .add_interactions(max_order=2)\n",
    ")\n",
    "\n",
    "model = SymbolicRegressor(\n",
    "    basis_library=library,\n",
    "    max_terms=4,\n",
    "    strategy=\"greedy_forward\",\n",
    ")\n",
    "model.fit(X, y)\n",
    "\n",
    "print(\"\\nDiscovered expression (log space):\")\n",
    "print(f\"  {model.expression_}\")\n",
    "print(f\"  R\u00b2 = {model.metrics_['r2']:.4f}\")\n",
    "\n",
    "# Extract exponents\n",
    "if \"ln_Re\" in model.selected_features_:\n",
    "    idx = model.selected_features_.index(\"ln_Re\")\n",
    "    re_exp = float(model.coefficients_[idx])\n",
    "    print(f\"\\nRe exponent: {re_exp:.2f} (true: 0.80)\")\n",
    "\n",
    "if \"ln_Pr\" in model.selected_features_:\n",
    "    idx = model.selected_features_.index(\"ln_Pr\")\n",
    "    pr_exp = float(model.coefficients_[idx])\n",
    "    print(f\"Pr exponent: {pr_exp:.2f} (true: 0.40)\")\n",
    "\n",
    "print(\"\\n--- Why the exponents differ from true values ---\")\n",
    "print(\"The spurious ln_Re*ln_Pr interaction term absorbs variance that should\")\n",
    "print(\"belong to individual terms, biasing the recovered exponents.\")\n",
    "if \"ln_Re\" in model.selected_features_:\n",
    "    idx = model.selected_features_.index(\"ln_Re\")\n",
    "    re_exp = float(model.coefficients_[idx])\n",
    "    print(f\"  - Re: {re_exp:.2f} vs true 0.80 (error: {abs(re_exp - 0.8)/0.8*100:.1f}%)\")\n",
    "if \"ln_Pr\" in model.selected_features_:\n",
    "    idx = model.selected_features_.index(\"ln_Pr\")\n",
    "    pr_exp = float(model.coefficients_[idx])\n",
    "    print(f\"  - Pr: {pr_exp:.2f} vs true 0.40 (error: {abs(pr_exp - 0.4)/0.4*100:.1f}%)\")\n",
    "print()\n",
    "print(\"Strategies for exact recovery:\")\n",
    "print(\"  1. Exclude interaction terms from basis library (if power law is known)\")\n",
    "print(\"  2. Use exhaustive search instead of greedy forward selection\")\n",
    "print(\"  3. Use parametric basis functions: add_parametric() with profile likelihood\")\n",
    "print(\"     (see langmuir_doe_active_learning.ipynb for example)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "w65r4i0m0sd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T22:35:26.373155Z",
     "iopub.status.busy": "2026-02-10T22:35:26.373069Z",
     "iopub.status.idle": "2026-02-10T22:35:26.995904Z",
     "shell.execute_reply": "2026-02-10T22:35:26.995416Z"
    }
   },
   "outputs": [],
   "source": [
    "# Parameter significance, diagnostics, and ANOVA\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats as sp_stats\n",
    "\n",
    "from jaxsr import anova\n",
    "from jaxsr.plotting import plot_parity\n",
    "\n",
    "intervals = model.coefficient_intervals(alpha=0.05)\n",
    "n_obs, k_terms = len(np.asarray(y)), len(model.selected_features_)\n",
    "df_resid = n_obs - k_terms\n",
    "\n",
    "print(\"Parameter Significance (95% CI):\")\n",
    "print(f\"  {'Term':>15s} {'Estimate':>10s} {'Std Err':>9s} {'t':>8s} {'p-value':>10s} 95% CI\")\n",
    "print(\"  \" + \"-\" * 75)\n",
    "for name, (est, lo, hi, se) in intervals.items():\n",
    "    t_val = est / se if abs(se) > 1e-15 else float(\"inf\")\n",
    "    p_val = float(2 * (1 - sp_stats.t.cdf(abs(t_val), df_resid))) if df_resid > 0 else 0.0\n",
    "    sig = \"***\" if p_val < 0.001 else (\"**\" if p_val < 0.01 else (\"*\" if p_val < 0.05 else \"\"))\n",
    "    print(f\"  {name:>15s} {est:10.4f} {se:9.4f} {t_val:8.2f} {p_val:10.2e} [{lo:.4f}, {hi:.4f}] {sig}\")\n",
    "print(\"  --- *** p<0.001, ** p<0.01, * p<0.05\")\n",
    "\n",
    "# Parity and residual plots\n",
    "y_pred = model.predict(X)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "plot_parity(y, y_pred, ax=axes[0], title=\"Forced Convection: Parity\")\n",
    "residuals = np.array(y - y_pred)\n",
    "axes[1].scatter(np.array(y_pred), residuals, alpha=0.6, c=\"steelblue\", edgecolors=\"white\", linewidth=0.5)\n",
    "axes[1].axhline(y=0, color=\"r\", linestyle=\"--\")\n",
    "axes[1].set_xlabel(\"Predicted\")\n",
    "axes[1].set_ylabel(\"Residuals\")\n",
    "axes[1].set_title(\"Forced Convection: Residuals\")\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ANOVA\n",
    "anova_result = anova(model)\n",
    "summary_sources = {\"Model\", \"Residual\", \"Total\"}\n",
    "print(\"\\nANOVA Table (Forced Convection)\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"  {'Source':25s}  {'DF':>4}  {'Sum Sq':>12}  {'Mean Sq':>12}  {'F':>10}  {'p-value':>10}\")\n",
    "print(\"-\" * 80)\n",
    "for row in anova_result.rows:\n",
    "    f_str = f\"{row.f_value:10.2f}\" if row.f_value is not None else \"          \"\n",
    "    p_str = f\"{row.p_value:10.4f}\" if row.p_value is not None else \"          \"\n",
    "    print(f\"  {row.source:25s}  {row.df:4d}  {row.sum_sq:12.4f}  {row.mean_sq:12.4f}  {f_str}  {p_str}\")\n",
    "print(\"-\" * 80)\n",
    "term_rows = [r for r in anova_result.rows if r.source not in summary_sources]\n",
    "if term_rows:\n",
    "    model_ss = sum(r.sum_sq for r in term_rows)\n",
    "    print(\"\\nVariance Contributions:\")\n",
    "    print(\"(Percentages relative to Model SS, not Total SS \u2014 shows relative importance within fitted model)\")\n",
    "    for row in term_rows:\n",
    "        pct = 100 * row.sum_sq / model_ss if model_ss > 0 else 0\n",
    "        sig = (\n",
    "            \"***\" if row.p_value is not None and row.p_value < 0.001 else (\n",
    "            \"**\" if row.p_value is not None and row.p_value < 0.01 else (\n",
    "            \"*\" if row.p_value is not None and row.p_value < 0.05 else \"\"))\n",
    "        )\n",
    "        print(f\"  {row.source:25s}  {pct:6.1f}%  {sig}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dittus-boelter-note",
   "metadata": {},
   "source": [
    "### Interpretation: Dittus-Boelter exponent recovery\n",
    "\n",
    "The discovered expression recovers the power-law structure of the Dittus-Boelter\n",
    "correlation but with noticeable deviations in the exponents:\n",
    "\n",
    "- **Re exponent**: 0.77 vs. true 0.80 (approximately 4% low)\n",
    "- **Pr exponent**: 0.34 vs. true 0.40 (approximately 15% low)\n",
    "\n",
    "The model also includes a spurious `ln_Re*ln_Pr` interaction term. In the original\n",
    "(non-log) space, this interaction corresponds to a `Re^a * Pr^b` coupling that is\n",
    "not present in the true correlation. This term absorbs some of the variance that\n",
    "should be attributed to the individual `ln_Re` and `ln_Pr` terms, pulling their\n",
    "coefficients (i.e., the recovered exponents) away from the true values.\n",
    "\n",
    "This is a known behavior of greedy forward selection: the interaction term may be\n",
    "selected early because it greedily reduces the residual sum of squares before the\n",
    "correct individual terms are fully established at their true coefficients. Once the\n",
    "interaction term is in the model, the remaining terms adjust their coefficients to\n",
    "compensate, leading to biased exponent estimates.\n",
    "\n",
    "**Strategies for exact recovery:**\n",
    "- Use a more constrained basis library containing only `ln_Re`, `ln_Pr`, and a\n",
    "  constant (excluding interaction terms), since the true model is known to be a\n",
    "  simple power law.\n",
    "- Use exhaustive search instead of greedy forward selection to evaluate all\n",
    "  candidate subsets.\n",
    "- Use parametric (nonlinear) basis functions to fit `Re^a` and `Pr^b` directly,\n",
    "  rather than relying on the log-space linearization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aff9727",
   "metadata": {},
   "source": [
    "## Discover natural convection correlation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7350326",
   "metadata": {},
   "source": [
    "**True model (vertical plate, laminar):**\n",
    "\n",
    "$$\\mathrm{Nu} = 0.59\\,\\mathrm{Ra}^{0.25}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ca4016d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T22:35:26.997378Z",
     "iopub.status.busy": "2026-02-10T22:35:26.997257Z",
     "iopub.status.idle": "2026-02-10T22:35:27.416473Z",
     "shell.execute_reply": "2026-02-10T22:35:27.416100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "True model: Nu = 0.59 * Ra^0.25\n",
      "Log form: log10(Nu) = -0.229 + 0.25*log10(Ra)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Discovered expression:\n",
      "  y = - 0.2709 + 0.2549*log_Ra\n",
      "  R\u00b2 = 0.9884\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "n_samples = 80\n",
    "\n",
    "# Rayleigh number range for laminar flow\n",
    "Ra = np.random.uniform(1e4, 1e9, n_samples)\n",
    "\n",
    "# Churchill-Chu correlation (simplified for laminar)\n",
    "C = 0.59\n",
    "n = 0.25\n",
    "Nu_true = C * Ra**n\n",
    "Nu = Nu_true * (1 + np.random.randn(n_samples) * 0.03)\n",
    "\n",
    "# Log transformation\n",
    "log_Ra = np.log10(Ra)\n",
    "log_Nu = np.log10(Nu)\n",
    "\n",
    "X = jnp.array(log_Ra).reshape(-1, 1)\n",
    "y = jnp.array(log_Nu)\n",
    "\n",
    "print(\"\\nTrue model: Nu = 0.59 * Ra^0.25\")\n",
    "print(f\"Log form: log10(Nu) = {np.log10(C):.3f} + 0.25*log10(Ra)\")\n",
    "\n",
    "library = BasisLibrary(n_features=1, feature_names=[\"log_Ra\"]).add_constant().add_linear()\n",
    "\n",
    "model = SymbolicRegressor(\n",
    "    basis_library=library,\n",
    "    max_terms=2,\n",
    "    strategy=\"exhaustive\",\n",
    ")\n",
    "model.fit(X, y)\n",
    "\n",
    "print(\"\\nDiscovered expression:\")\n",
    "print(f\"  {model.expression_}\")\n",
    "print(f\"  R\u00b2 = {model.metrics_['r2']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "nph3axmxlc8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T22:35:27.417753Z",
     "iopub.status.busy": "2026-02-10T22:35:27.417665Z",
     "iopub.status.idle": "2026-02-10T22:35:27.776174Z",
     "shell.execute_reply": "2026-02-10T22:35:27.775744Z"
    }
   },
   "outputs": [],
   "source": [
    "# Diagnostics and ANOVA for natural convection\n",
    "intervals = model.coefficient_intervals(alpha=0.05)\n",
    "n_obs, k_terms = len(np.asarray(y)), len(model.selected_features_)\n",
    "df_resid = n_obs - k_terms\n",
    "\n",
    "print(\"Parameter Significance (95% CI):\")\n",
    "print(f\"  {'Term':>15s} {'Estimate':>10s} {'Std Err':>9s} {'t':>8s} {'p-value':>10s} 95% CI\")\n",
    "print(\"  \" + \"-\" * 75)\n",
    "for name, (est, lo, hi, se) in intervals.items():\n",
    "    t_val = est / se if abs(se) > 1e-15 else float(\"inf\")\n",
    "    p_val = float(2 * (1 - sp_stats.t.cdf(abs(t_val), df_resid))) if df_resid > 0 else 0.0\n",
    "    sig = \"***\" if p_val < 0.001 else (\"**\" if p_val < 0.01 else (\"*\" if p_val < 0.05 else \"\"))\n",
    "    print(f\"  {name:>15s} {est:10.4f} {se:9.4f} {t_val:8.2f} {p_val:10.2e} [{lo:.4f}, {hi:.4f}] {sig}\")\n",
    "print(\"  --- *** p<0.001, ** p<0.01, * p<0.05\")\n",
    "\n",
    "y_pred = model.predict(X)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "plot_parity(y, y_pred, ax=axes[0], title=\"Natural Convection: Parity\")\n",
    "residuals = np.array(y - y_pred)\n",
    "axes[1].scatter(np.array(y_pred), residuals, alpha=0.6, c=\"steelblue\", edgecolors=\"white\", linewidth=0.5)\n",
    "axes[1].axhline(y=0, color=\"r\", linestyle=\"--\")\n",
    "axes[1].set_xlabel(\"Predicted\")\n",
    "axes[1].set_ylabel(\"Residuals\")\n",
    "axes[1].set_title(\"Natural Convection: Residuals\")\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "anova_result = anova(model)\n",
    "summary_sources = {\"Model\", \"Residual\", \"Total\"}\n",
    "print(\"\\nANOVA Table (Natural Convection)\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"  {'Source':25s}  {'DF':>4}  {'Sum Sq':>12}  {'Mean Sq':>12}  {'F':>10}  {'p-value':>10}\")\n",
    "print(\"-\" * 80)\n",
    "for row in anova_result.rows:\n",
    "    f_str = f\"{row.f_value:10.2f}\" if row.f_value is not None else \"          \"\n",
    "    p_str = f\"{row.p_value:10.4f}\" if row.p_value is not None else \"          \"\n",
    "    print(f\"  {row.source:25s}  {row.df:4d}  {row.sum_sq:12.4f}  {row.mean_sq:12.4f}  {f_str}  {p_str}\")\n",
    "print(\"-\" * 80)\n",
    "term_rows = [r for r in anova_result.rows if r.source not in summary_sources]\n",
    "if term_rows:\n",
    "    model_ss = sum(r.sum_sq for r in term_rows)\n",
    "    print(\"\\nVariance Contributions:\")\n",
    "    print(\"(Percentages relative to Model SS, not Total SS \u2014 shows relative importance within fitted model)\")\n",
    "    for row in term_rows:\n",
    "        pct = 100 * row.sum_sq / model_ss if model_ss > 0 else 0\n",
    "        sig = (\n",
    "            \"***\" if row.p_value is not None and row.p_value < 0.001 else (\n",
    "            \"**\" if row.p_value is not None and row.p_value < 0.01 else (\n",
    "            \"*\" if row.p_value is not None and row.p_value < 0.05 else \"\"))\n",
    "        )\n",
    "        print(f\"  {row.source:25s}  {pct:6.1f}%  {sig}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79202850",
   "metadata": {},
   "source": [
    "## Discover fin efficiency correlation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863bc2db",
   "metadata": {},
   "source": [
    "**True model:**\n",
    "\n",
    "$$\\eta = \\frac{\\tanh(mL)}{mL}, \\quad mL = \\sqrt{\\frac{hP}{kA}}\\,L$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b82ff86b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T22:35:27.777783Z",
     "iopub.status.busy": "2026-02-10T22:35:27.777673Z",
     "iopub.status.idle": "2026-02-10T22:35:28.696900Z",
     "shell.execute_reply": "2026-02-10T22:35:28.696350Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "True model: eta = tanh(mL) / mL\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Discovered expression:\n",
      "  y = 1.001*tanh(mL)/mL\n",
      "  R\u00b2 = 0.9984\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "n_samples = 100\n",
    "\n",
    "# mL parameter (dimensionless fin parameter)\n",
    "mL = np.random.uniform(0.1, 3.0, n_samples)\n",
    "\n",
    "# True fin efficiency\n",
    "eta_true = np.tanh(mL) / mL\n",
    "eta = eta_true + np.random.randn(n_samples) * 0.01\n",
    "\n",
    "X = jnp.array(mL).reshape(-1, 1)\n",
    "y = jnp.array(eta)\n",
    "\n",
    "print(\"\\nTrue model: eta = tanh(mL) / mL\")\n",
    "\n",
    "# Build library with hyperbolic functions\n",
    "library = (\n",
    "    BasisLibrary(n_features=1, feature_names=[\"mL\"])\n",
    "    .add_constant()\n",
    "    .add_linear()\n",
    "    .add_polynomials(max_degree=4)\n",
    "    .add_transcendental([\"tanh\", \"inv\"])\n",
    ")\n",
    "\n",
    "# Add the exact form as a custom function\n",
    "library.add_custom(\n",
    "    name=\"tanh(mL)/mL\",\n",
    "    func=lambda X: jnp.tanh(X[:, 0]) / X[:, 0],\n",
    "    complexity=3,\n",
    ")\n",
    "\n",
    "# Constraint: efficiency must be between 0 and 1\n",
    "constraints = Constraints().add_bounds(\"y\", lower=0.0, upper=1.0)\n",
    "\n",
    "model = SymbolicRegressor(\n",
    "    basis_library=library,\n",
    "    max_terms=3,\n",
    "    strategy=\"greedy_forward\",\n",
    "    constraints=constraints,\n",
    ")\n",
    "model.fit(X, y)\n",
    "\n",
    "print(\"\\nDiscovered expression:\")\n",
    "print(f\"  {model.expression_}\")\n",
    "print(f\"  R\u00b2 = {model.metrics_['r2']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ooausiwaj",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T22:35:28.698280Z",
     "iopub.status.busy": "2026-02-10T22:35:28.698181Z",
     "iopub.status.idle": "2026-02-10T22:35:28.901211Z",
     "shell.execute_reply": "2026-02-10T22:35:28.900606Z"
    }
   },
   "outputs": [],
   "source": [
    "# Diagnostics and ANOVA for fin efficiency\n",
    "intervals = model.coefficient_intervals(alpha=0.05)\n",
    "n_obs, k_terms = len(np.asarray(y)), len(model.selected_features_)\n",
    "df_resid = n_obs - k_terms\n",
    "\n",
    "print(\"Parameter Significance (95% CI):\")\n",
    "print(f\"  {'Term':>15s} {'Estimate':>10s} {'Std Err':>9s} {'t':>8s} {'p-value':>10s} 95% CI\")\n",
    "print(\"  \" + \"-\" * 75)\n",
    "for name, (est, lo, hi, se) in intervals.items():\n",
    "    t_val = est / se if abs(se) > 1e-15 else float(\"inf\")\n",
    "    p_val = float(2 * (1 - sp_stats.t.cdf(abs(t_val), df_resid))) if df_resid > 0 else 0.0\n",
    "    sig = \"***\" if p_val < 0.001 else (\"**\" if p_val < 0.01 else (\"*\" if p_val < 0.05 else \"\"))\n",
    "    print(f\"  {name:>15s} {est:10.4f} {se:9.4f} {t_val:8.2f} {p_val:10.2e} [{lo:.4f}, {hi:.4f}] {sig}\")\n",
    "print(\"  --- *** p<0.001, ** p<0.01, * p<0.05\")\n",
    "\n",
    "y_pred = model.predict(X)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "plot_parity(y, y_pred, ax=axes[0], title=\"Fin Efficiency: Parity\")\n",
    "residuals = np.array(y - y_pred)\n",
    "axes[1].scatter(np.array(y_pred), residuals, alpha=0.6, c=\"steelblue\", edgecolors=\"white\", linewidth=0.5)\n",
    "axes[1].axhline(y=0, color=\"r\", linestyle=\"--\")\n",
    "axes[1].set_xlabel(\"Predicted\")\n",
    "axes[1].set_ylabel(\"Residuals\")\n",
    "axes[1].set_title(\"Fin Efficiency: Residuals\")\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "anova_result = anova(model)\n",
    "summary_sources = {\"Model\", \"Residual\", \"Total\"}\n",
    "print(\"\\nANOVA Table (Fin Efficiency)\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"  {'Source':25s}  {'DF':>4}  {'Sum Sq':>12}  {'Mean Sq':>12}  {'F':>10}  {'p-value':>10}\")\n",
    "print(\"-\" * 80)\n",
    "for row in anova_result.rows:\n",
    "    f_str = f\"{row.f_value:10.2f}\" if row.f_value is not None else \"          \"\n",
    "    p_str = f\"{row.p_value:10.4f}\" if row.p_value is not None else \"          \"\n",
    "    print(f\"  {row.source:25s}  {row.df:4d}  {row.sum_sq:12.4f}  {row.mean_sq:12.4f}  {f_str}  {p_str}\")\n",
    "print(\"-\" * 80)\n",
    "term_rows = [r for r in anova_result.rows if r.source not in summary_sources]\n",
    "if term_rows:\n",
    "    model_ss = sum(r.sum_sq for r in term_rows)\n",
    "    print(\"\\nVariance Contributions:\")\n",
    "    print(\"(Percentages relative to Model SS, not Total SS \u2014 shows relative importance within fitted model)\")\n",
    "    for row in term_rows:\n",
    "        pct = 100 * row.sum_sq / model_ss if model_ss > 0 else 0\n",
    "        sig = (\n",
    "            \"***\" if row.p_value is not None and row.p_value < 0.001 else (\n",
    "            \"**\" if row.p_value is not None and row.p_value < 0.01 else (\n",
    "            \"*\" if row.p_value is not None and row.p_value < 0.05 else \"\"))\n",
    "        )\n",
    "        print(f\"  {row.source:25s}  {pct:6.1f}%  {sig}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec5c9aa",
   "metadata": {},
   "source": [
    "## Discover heat exchanger effectiveness-NTU relationship."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6789080b",
   "metadata": {},
   "source": [
    "**True model (parallel flow):**\n",
    "\n",
    "$$\\varepsilon = \\frac{1 - e^{-\\mathrm{NTU}(1+C)}}{1+C}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e5911b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T22:35:28.902717Z",
     "iopub.status.busy": "2026-02-10T22:35:28.902617Z",
     "iopub.status.idle": "2026-02-10T22:35:30.595142Z",
     "shell.execute_reply": "2026-02-10T22:35:30.594703Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "n_samples = 120\n",
    "\n",
    "# NTU and capacity ratio\n",
    "NTU = np.random.uniform(0.1, 5.0, n_samples)\n",
    "C = np.random.uniform(0.0, 1.0, n_samples)\n",
    "\n",
    "# Parallel flow effectiveness\n",
    "eps_true = (1 - np.exp(-NTU * (1 + C))) / (1 + C)\n",
    "eps = eps_true + np.random.randn(n_samples) * 0.01\n",
    "\n",
    "X = jnp.column_stack([NTU, C])\n",
    "y = jnp.array(eps)\n",
    "\n",
    "print(\"\\nTrue model: eps = (1 - exp(-NTU*(1+C))) / (1+C)\")\n",
    "\n",
    "library = (\n",
    "    BasisLibrary(n_features=2, feature_names=[\"NTU\", \"C\"])\n",
    "    .add_constant()\n",
    "    .add_linear()\n",
    "    .add_polynomials(max_degree=2)\n",
    "    .add_interactions(max_order=2)\n",
    "    .add_transcendental([\"exp\"])\n",
    ")\n",
    "\n",
    "# Add specific forms\n",
    "library.add_custom(\n",
    "    name=\"exp(-NTU)\",\n",
    "    func=lambda X: jnp.exp(-X[:, 0]),\n",
    "    complexity=2,\n",
    ")\n",
    "library.add_custom(\n",
    "    name=\"exp(-NTU*(1+C))\",\n",
    "    func=lambda X: jnp.exp(-X[:, 0] * (1 + X[:, 1])),\n",
    "    complexity=3,\n",
    ")\n",
    "library.add_custom(\n",
    "    name=\"1/(1+C)\",\n",
    "    func=lambda X: 1 / (1 + X[:, 1]),\n",
    "    complexity=2,\n",
    ")\n",
    "\n",
    "# Effectiveness between 0 and 1\n",
    "constraints = Constraints().add_bounds(\"y\", lower=0.0, upper=1.0)\n",
    "\n",
    "model = SymbolicRegressor(\n",
    "    basis_library=library,\n",
    "    max_terms=5,\n",
    "    strategy=\"greedy_forward\",\n",
    "    constraints=constraints,\n",
    ")\n",
    "model.fit(X, y)\n",
    "\n",
    "print(\"\\nDiscovered expression:\")\n",
    "print(f\"  {model.expression_}\")\n",
    "print(f\"  R\u00b2 = {model.metrics_['r2']:.4f}\")\n",
    "\n",
    "print(\"\\n--- Structural Limitation of Linear Basis Approach ---\")\n",
    "print(\"True form: \u03b5 = [1 - exp(-NTU*(1+C))] / (1+C)\")\n",
    "print()\n",
    "print(\"This is a PRODUCT of two nonlinear terms, not a linear combination.\")\n",
    "print(\"A linear SR model can only assign CONSTANT coefficients to each basis function.\")\n",
    "print(\"True model requires coefficient on exp() term to vary with C as -1/(1+C),\")\n",
    "print(\"which is not representable in linear-in-parameters form.\")\n",
    "print()\n",
    "print(\"Despite this limitation, the polynomial approximation achieves excellent fit\")\n",
    "print(\"(R\u00b2 > 0.99) and is practical for interpolation within the sampled range.\")\n",
    "print(\"Caution: Extrapolation beyond training range may be inaccurate.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6j9t6cy1ivu",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T22:35:30.596499Z",
     "iopub.status.busy": "2026-02-10T22:35:30.596399Z",
     "iopub.status.idle": "2026-02-10T22:35:31.019383Z",
     "shell.execute_reply": "2026-02-10T22:35:31.018865Z"
    }
   },
   "outputs": [],
   "source": [
    "# Diagnostics and ANOVA for heat exchanger\n",
    "intervals = model.coefficient_intervals(alpha=0.05)\n",
    "n_obs, k_terms = len(np.asarray(y)), len(model.selected_features_)\n",
    "df_resid = n_obs - k_terms\n",
    "\n",
    "print(\"Parameter Significance (95% CI):\")\n",
    "print(f\"  {'Term':>15s} {'Estimate':>10s} {'Std Err':>9s} {'t':>8s} {'p-value':>10s} 95% CI\")\n",
    "print(\"  \" + \"-\" * 75)\n",
    "for name, (est, lo, hi, se) in intervals.items():\n",
    "    t_val = est / se if abs(se) > 1e-15 else float(\"inf\")\n",
    "    p_val = float(2 * (1 - sp_stats.t.cdf(abs(t_val), df_resid))) if df_resid > 0 else 0.0\n",
    "    sig = \"***\" if p_val < 0.001 else (\"**\" if p_val < 0.01 else (\"*\" if p_val < 0.05 else \"\"))\n",
    "    print(f\"  {name:>15s} {est:10.4f} {se:9.4f} {t_val:8.2f} {p_val:10.2e} [{lo:.4f}, {hi:.4f}] {sig}\")\n",
    "print(\"  --- *** p<0.001, ** p<0.01, * p<0.05\")\n",
    "\n",
    "y_pred = model.predict(X)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "plot_parity(y, y_pred, ax=axes[0], title=\"Heat Exchanger: Parity\")\n",
    "residuals = np.array(y - y_pred)\n",
    "axes[1].scatter(np.array(y_pred), residuals, alpha=0.6, c=\"steelblue\", edgecolors=\"white\", linewidth=0.5)\n",
    "axes[1].axhline(y=0, color=\"r\", linestyle=\"--\")\n",
    "axes[1].set_xlabel(\"Predicted\")\n",
    "axes[1].set_ylabel(\"Residuals\")\n",
    "axes[1].set_title(\"Heat Exchanger: Residuals\")\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "anova_result = anova(model)\n",
    "summary_sources = {\"Model\", \"Residual\", \"Total\"}\n",
    "print(\"\\nANOVA Table (Heat Exchanger)\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"  {'Source':25s}  {'DF':>4}  {'Sum Sq':>12}  {'Mean Sq':>12}  {'F':>10}  {'p-value':>10}\")\n",
    "print(\"-\" * 80)\n",
    "for row in anova_result.rows:\n",
    "    f_str = f\"{row.f_value:10.2f}\" if row.f_value is not None else \"          \"\n",
    "    p_str = f\"{row.p_value:10.4f}\" if row.p_value is not None else \"          \"\n",
    "    print(f\"  {row.source:25s}  {row.df:4d}  {row.sum_sq:12.4f}  {row.mean_sq:12.4f}  {f_str}  {p_str}\")\n",
    "print(\"-\" * 80)\n",
    "term_rows = [r for r in anova_result.rows if r.source not in summary_sources]\n",
    "if term_rows:\n",
    "    model_ss = sum(r.sum_sq for r in term_rows)\n",
    "    print(\"\\nVariance Contributions:\")\n",
    "    print(\"(Percentages relative to Model SS, not Total SS \u2014 shows relative importance within fitted model)\")\n",
    "    for row in term_rows:\n",
    "        pct = 100 * row.sum_sq / model_ss if model_ss > 0 else 0\n",
    "        sig = (\n",
    "            \"***\" if row.p_value is not None and row.p_value < 0.001 else (\n",
    "            \"**\" if row.p_value is not None and row.p_value < 0.01 else (\n",
    "            \"*\" if row.p_value is not None and row.p_value < 0.05 else \"\"))\n",
    "        )\n",
    "        print(f\"  {row.source:25s}  {pct:6.1f}%  {sig}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heat-exchanger-note",
   "metadata": {},
   "source": [
    "### Interpretation: effectiveness-NTU structural limitations\n",
    "\n",
    "The discovered model achieves an excellent R-squared of 0.991 but does not\n",
    "recover the exact analytical form. The key discrepancies are:\n",
    "\n",
    "- The coefficient on `1/(1+C)` is 0.878 (true: 1.0).\n",
    "- The coefficient on `exp(-NTU*(1+C))` is a constant -0.627, whereas in the true\n",
    "  expression `(1 - exp(-NTU*(1+C))) / (1+C)`, the effective coefficient on the\n",
    "  exponential term is `-1/(1+C)`, which varies with C.\n",
    "- The model compensates with three additional correction terms (`C`, `NTU*C`,\n",
    "  `NTU`) that approximate the residual error from the structural mismatch.\n",
    "\n",
    "This is a **structural limitation** of the linear-combination basis approach.\n",
    "The true form is a product of two nonlinear terms:\n",
    "\n",
    "$$\\varepsilon = \\frac{1}{1+C} \\cdot \\bigl(1 - e^{-\\mathrm{NTU}(1+C)}\\bigr)$$\n",
    "\n",
    "This product cannot be exactly represented as a linear combination of the\n",
    "library's basis functions, because the coefficient on `exp(-NTU*(1+C))` in the\n",
    "true model is itself a function of C (specifically, `-1/(1+C)`), not a constant.\n",
    "A linear symbolic regression model can only assign constant coefficients to each\n",
    "basis function, so it cannot capture this coupling exactly.\n",
    "\n",
    "Despite this structural limitation, the R-squared of 0.991 indicates that the\n",
    "five-term approximation is practically excellent across the sampled NTU and C\n",
    "ranges. For exact recovery, one would need to include the composite basis\n",
    "function `exp(-NTU*(1+C))/(1+C)` directly in the library, or use a nonlinear\n",
    "regression approach that allows variable-dependent coefficients."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}