{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0501d7d",
   "metadata": {},
   "source": [
    "# Chemical Kinetics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4862015",
   "metadata": {},
   "source": [
    "Chemical Kinetics Example for JAXSR.\n",
    "\n",
    "Demonstrates discovering rate laws from kinetic data, including:\n",
    "- Langmuir-Hinshelwood kinetics\n",
    "- Power law kinetics\n",
    "- Arrhenius temperature dependence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10badec1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T22:36:12.771218Z",
     "iopub.status.busy": "2026-02-10T22:36:12.771132Z",
     "iopub.status.idle": "2026-02-10T22:36:13.252015Z",
     "shell.execute_reply": "2026-02-10T22:36:13.251686Z"
    }
   },
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "from jaxsr import BasisLibrary, Constraints, SymbolicRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ecdf3e",
   "metadata": {},
   "source": [
    "## Discover Langmuir-Hinshelwood rate law."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10b5660",
   "metadata": {},
   "source": [
    "True model:\n",
    "\n",
    "$$r = \\frac{k\\,C_A\\,C_B}{1 + K\\,C_A}, \\quad k=2.5,\\; K=1.2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d4eaac6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T22:36:13.253477Z",
     "iopub.status.busy": "2026-02-10T22:36:13.253371Z",
     "iopub.status.idle": "2026-02-10T22:36:16.208462Z",
     "shell.execute_reply": "2026-02-10T22:36:16.208077Z"
    }
   },
   "outputs": [],
   "source": [
    "# Generate synthetic kinetic datanp.random.seed(42)n_samples = 100# Concentration ranges typical for catalytic reactionsC_A = np.random.uniform(0.1, 2.0, n_samples)C_B = np.random.uniform(0.1, 2.0, n_samples)# True kinetic parametersk = 2.5  # Rate constantK = 1.2  # Adsorption equilibrium constant# True rate lawr_true = k * C_A * C_B / (1 + K * C_A)r = r_true + np.random.randn(n_samples) * 0.05X = jnp.column_stack([C_A, C_B])y = jnp.array(r)print(\"\\nTrue model: r = 2.5*C_A*C_B / (1 + 1.2*C_A)\")print(f\"Data: {n_samples} samples\")# Build basis library with appropriate functions for kineticslibrary = (    BasisLibrary(n_features=2, feature_names=[\"C_A\", \"C_B\"])    .add_constant()    .add_linear()    .add_polynomials(max_degree=2)    .add_interactions(max_order=2)    .add_ratios()    .add_transcendental([\"inv\"]))print(f\"Basis library: {len(library)} candidate functions\")# Add constraint: reaction rate must be non-negativeconstraints = Constraints().add_bounds(\"y\", lower=0)\n",
    "# \u26a0\ufe0f Constraint Enforcement Note: This uses soft enforcement (hard=False by default).\n",
    "# Predictions may still go slightly negative at boundary regions.\n",
    "# For strict non-negativity everywhere, use:\n",
    "#   constraints = Constraints().add_bounds(\"y\", lower=0, hard=True)\n",
    "#   model = SymbolicRegressor(..., constraint_enforcement=\"exact\")# Fit modelmodel = SymbolicRegressor(    basis_library=library,    max_terms=6,    strategy=\"greedy_forward\",    information_criterion=\"bic\",    constraints=constraints,)model.fit(X, y)print(\"\\nDiscovered expression:\")print(f\"  {model.expression_}\")print(\"\\n--- Mechanistic vs Empirical Models ---\")print(\"This polynomial-rational expression provides good empirical fit (R\u00b2 shown above),\")print(\"but does NOT give mechanistic parameters k and K from the L-H rate law.\")print()print(\"To recover exact L-H form:  r = k*C_A*C_B/(1+K*C_A)\")print(\"  1. Use add_parametric() to define L-H basis function\")print(\"  2. Fit with profile_params=['K'] to optimize adsorption constant\")print(\"  3. Extract k from coefficient, K from optimized parameter\")print(\"  4. See model_comparison_isotherms.ipynb for complete parametric example\")print()print(\"When to use parametric vs exploratory:\")print(\"  \u2022 Parametric (mechanistic): Known functional form, interpretable parameters\")print(\"  \u2022 Exploratory (polynomial): Unknown form, empirical approximation\")print(\"\\nMetrics:\")print(f\"  R\u00b2 = {model.metrics_['r2']:.4f}\")print(f\"  MSE = {model.metrics_['mse']:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note on soft bounds constraints\n\n`add_bounds(\"y\", lower=0)` uses **soft enforcement by default** (`hard=False`), which adds a penalty term during coefficient refit but does not guarantee non-negativity everywhere. The model's negative intercept (`-0.10`) means predictions could be negative for very small concentrations. For strict non-negativity, use `hard=True` or pass `constraint_enforcement=\"exact\"` to the `SymbolicRegressor` constructor."
   ],
   "id": "98c6dc04"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fz5gfdlq2td",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T22:36:16.209770Z",
     "iopub.status.busy": "2026-02-10T22:36:16.209695Z",
     "iopub.status.idle": "2026-02-10T22:36:16.890526Z",
     "shell.execute_reply": "2026-02-10T22:36:16.890042Z"
    }
   },
   "outputs": [],
   "source": [
    "# Parameter significance, diagnostics, and ANOVA\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats as sp_stats\n",
    "from jaxsr import anova\n",
    "from jaxsr.plotting import plot_parity\n",
    "\n",
    "intervals = model.coefficient_intervals(alpha=0.05)\n",
    "n_obs, k_terms = len(np.asarray(y)), len(model.selected_features_)\n",
    "df_resid = n_obs - k_terms\n",
    "\n",
    "print(\"Parameter Significance (95% CI):\")\n",
    "print(f\"  {'Term':>15s} {'Estimate':>10s} {'Std Err':>9s} {'t':>8s} {'p-value':>10s} 95% CI\")\n",
    "print(\"  \" + \"-\" * 75)\n",
    "for name, (est, lo, hi, se) in intervals.items():\n",
    "    t_val = est / se if abs(se) > 1e-15 else float(\"inf\")\n",
    "    p_val = float(2 * (1 - sp_stats.t.cdf(abs(t_val), df_resid))) if df_resid > 0 else 0.0\n",
    "    sig = \"***\" if p_val < 0.001 else (\"**\" if p_val < 0.01 else (\"*\" if p_val < 0.05 else \"\"))\n",
    "    print(f\"  {name:>15s} {est:10.4f} {se:9.4f} {t_val:8.2f} {p_val:10.2e} [{lo:.4f}, {hi:.4f}] {sig}\")\n",
    "print(\"  --- *** p<0.001, ** p<0.01, * p<0.05\")\n",
    "\n",
    "y_pred = model.predict(X)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "plot_parity(y, y_pred, ax=axes[0], title=\"Langmuir-Hinshelwood: Parity\")\n",
    "residuals = np.array(y - y_pred)\n",
    "axes[1].scatter(np.array(y_pred), residuals, alpha=0.6, c=\"steelblue\", edgecolors=\"white\", linewidth=0.5)\n",
    "axes[1].axhline(y=0, color=\"r\", linestyle=\"--\")\n",
    "axes[1].set_xlabel(\"Predicted\")\n",
    "axes[1].set_ylabel(\"Residuals\")\n",
    "axes[1].set_title(\"Langmuir-Hinshelwood: Residuals\")\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "anova_result = anova(model)\n",
    "summary_sources = {\"Model\", \"Residual\", \"Total\"}\n",
    "print(\"\\nANOVA Table (Langmuir-Hinshelwood)\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"  {'Source':25s}  {'DF':>4}  {'Sum Sq':>12}  {'Mean Sq':>12}  {'F':>10}  {'p-value':>10}\")\n",
    "print(\"-\" * 80)\n",
    "for row in anova_result.rows:\n",
    "    f_str = f\"{row.f_value:10.2f}\" if row.f_value is not None else \"          \"\n",
    "    p_str = f\"{row.p_value:10.4f}\" if row.p_value is not None else \"          \"\n",
    "    print(f\"  {row.source:25s}  {row.df:4d}  {row.sum_sq:12.4f}  {row.mean_sq:12.4f}  {f_str}  {p_str}\")\n",
    "print(\"-\" * 80)\n",
    "term_rows = [r for r in anova_result.rows if r.source not in summary_sources]\n",
    "if term_rows:\n",
    "    model_ss = sum(r.sum_sq for r in term_rows)\n",
    "    print(\"\\nVariance Contributions:\")\n",
    "    print(\"(Percentages relative to Model SS, not Total SS \u2014 shows relative importance within fitted model)\")\n",
    "    for row in term_rows:\n",
    "        pct = 100 * row.sum_sq / model_ss if model_ss > 0 else 0\n",
    "        sig = (\n",
    "            \"***\" if row.p_value is not None and row.p_value < 0.001 else (\n",
    "            \"**\" if row.p_value is not None and row.p_value < 0.01 else (\n",
    "            \"*\" if row.p_value is not None and row.p_value < 0.05 else \"\"))\n",
    "        )\n",
    "        print(f\"  {row.source:25s}  {pct:6.1f}%  {sig}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f16b6c",
   "metadata": {},
   "source": [
    "### Note on the discovered expression\n",
    "\n",
    "The discovered 6-term polynomial-rational expression provides a good empirical fit\n",
    "(R^2 = 0.993) but is **not** the true Langmuir-Hinshelwood form\n",
    "`r = k*C_A*C_B / (1 + K*C_A)`. This is expected: the basis library does not include\n",
    "the exact L-H functional form as a single basis function, so JAXSR approximates the\n",
    "underlying relationship using the available building blocks (polynomials, ratios, etc.).\n",
    "\n",
    "Because the discovered expression is a polynomial approximation rather than the\n",
    "mechanistic form, we cannot extract the physically meaningful rate constant *k* or\n",
    "adsorption equilibrium constant *K* from the fitted coefficients.\n",
    "\n",
    "**Soft bounds constraint.** The `add_bounds(\"y\", lower=0)` constraint used above is\n",
    "**soft** by default (`hard=False`), meaning it penalizes but does not strictly prevent\n",
    "negative predictions. Since the model includes a negative intercept (-0.1014),\n",
    "predictions could go negative for small concentrations near the boundary of the\n",
    "training domain. Pass `hard=True` to enforce strict non-negativity.\n",
    "\n",
    "**Recovering the exact L-H form.** If the functional form is known (or hypothesized),\n",
    "use `add_parametric()` to encode it directly as a basis function. This enables JAXSR\n",
    "to fit the exact L-H expression with identifiable physical parameters, as demonstrated\n",
    "in the `model_comparison_isotherms` and `langmuir_doe_active_learning` notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad8abf6",
   "metadata": {},
   "source": [
    "## Discover power law kinetics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5f1df9",
   "metadata": {},
   "source": [
    "True model:\n",
    "\n",
    "$$r = 1.5\\,C_A^{1.0}\\,C_B^{0.5}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a90914c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T22:36:16.891930Z",
     "iopub.status.busy": "2026-02-10T22:36:16.891808Z",
     "iopub.status.idle": "2026-02-10T22:36:17.230843Z",
     "shell.execute_reply": "2026-02-10T22:36:17.230498Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "n_samples = 100\n",
    "\n",
    "C_A = np.random.uniform(0.5, 3.0, n_samples)\n",
    "C_B = np.random.uniform(0.5, 3.0, n_samples)\n",
    "\n",
    "# True parameters\n",
    "k = 1.5\n",
    "a = 1.0  # First order in A\n",
    "b = 0.5  # Half order in B\n",
    "\n",
    "r_true = k * C_A**a * C_B**b\n",
    "r = r_true + np.random.randn(n_samples) * 0.02\n",
    "\n",
    "X = jnp.column_stack([C_A, C_B])\n",
    "y = jnp.array(r)\n",
    "\n",
    "print(\"\\nTrue model: r = 1.5 * C_A^1.0 * C_B^0.5\")\n",
    "\n",
    "# For power law, include sqrt for half-order\n",
    "library = (\n",
    "    BasisLibrary(n_features=2, feature_names=[\"C_A\", \"C_B\"])\n",
    "    .add_constant()\n",
    "    .add_linear()\n",
    "    .add_polynomials(max_degree=2)\n",
    "    .add_interactions(max_order=2)\n",
    "    .add_transcendental([\"sqrt\"])\n",
    ")\n",
    "\n",
    "# Add custom basis function for C_A * sqrt(C_B)\n",
    "library.add_custom(\n",
    "    name=\"C_A*sqrt(C_B)\",\n",
    "    func=lambda X: X[:, 0] * jnp.sqrt(X[:, 1]),\n",
    "    complexity=2,\n",
    ")\n",
    "\n",
    "model = SymbolicRegressor(\n",
    "    basis_library=library,\n",
    "    max_terms=5,\n",
    "    strategy=\"greedy_forward\",\n",
    ")\n",
    "model.fit(X, y)\n",
    "\n",
    "print(\"\\nDiscovered expression:\")\n",
    "print(f\"  {model.expression_}\")\n",
    "\n",
    "# Check for spurious/negligible terms\n",
    "print(\"\\nTerm significance:\")\n",
    "max_coef = max(abs(c) for c in model.coefficients_)\n",
    "for name, coef in zip(model.selected_features_, model.coefficients_, strict=False):\n",
    "    rel_magnitude = abs(coef) / max_coef\n",
    "    if rel_magnitude < 0.01:\n",
    "        flag = \"(negligible)\"\n",
    "    elif rel_magnitude > 0.5:\n",
    "        flag = \"(dominant)\"\n",
    "    else:\n",
    "        flag = \"\"\n",
    "    print(f\"  {name:15s}: {float(coef):10.4f}  {flag}\")\n",
    "print(f\"  R\u00b2 = {model.metrics_['r2']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "gpah7nd07lm",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T22:36:17.232175Z",
     "iopub.status.busy": "2026-02-10T22:36:17.232099Z",
     "iopub.status.idle": "2026-02-10T22:36:17.486567Z",
     "shell.execute_reply": "2026-02-10T22:36:17.486090Z"
    }
   },
   "outputs": [],
   "source": [
    "# Parameter significance, diagnostics, and ANOVA\n",
    "intervals = model.coefficient_intervals(alpha=0.05)\n",
    "n_obs, k_terms = len(np.asarray(y)), len(model.selected_features_)\n",
    "df_resid = n_obs - k_terms\n",
    "\n",
    "print(\"Parameter Significance (95% CI):\")\n",
    "print(f\"  {'Term':>15s} {'Estimate':>10s} {'Std Err':>9s} {'t':>8s} {'p-value':>10s} 95% CI\")\n",
    "print(\"  \" + \"-\" * 75)\n",
    "for name, (est, lo, hi, se) in intervals.items():\n",
    "    t_val = est / se if abs(se) > 1e-15 else float(\"inf\")\n",
    "    p_val = float(2 * (1 - sp_stats.t.cdf(abs(t_val), df_resid))) if df_resid > 0 else 0.0\n",
    "    sig = \"***\" if p_val < 0.001 else (\"**\" if p_val < 0.01 else (\"*\" if p_val < 0.05 else \"\"))\n",
    "    print(f\"  {name:>15s} {est:10.4f} {se:9.4f} {t_val:8.2f} {p_val:10.2e} [{lo:.4f}, {hi:.4f}] {sig}\")\n",
    "print(\"  --- *** p<0.001, ** p<0.01, * p<0.05\")\n",
    "\n",
    "y_pred = model.predict(X)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "plot_parity(y, y_pred, ax=axes[0], title=\"Power Law: Parity\")\n",
    "residuals = np.array(y - y_pred)\n",
    "axes[1].scatter(np.array(y_pred), residuals, alpha=0.6, c=\"steelblue\", edgecolors=\"white\", linewidth=0.5)\n",
    "axes[1].axhline(y=0, color=\"r\", linestyle=\"--\")\n",
    "axes[1].set_xlabel(\"Predicted\")\n",
    "axes[1].set_ylabel(\"Residuals\")\n",
    "axes[1].set_title(\"Power Law: Residuals\")\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "anova_result = anova(model)\n",
    "summary_sources = {\"Model\", \"Residual\", \"Total\"}\n",
    "print(\"\\nANOVA Table (Power Law)\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"  {'Source':25s}  {'DF':>4}  {'Sum Sq':>12}  {'Mean Sq':>12}  {'F':>10}  {'p-value':>10}\")\n",
    "print(\"-\" * 80)\n",
    "for row in anova_result.rows:\n",
    "    f_str = f\"{row.f_value:10.2f}\" if row.f_value is not None else \"          \"\n",
    "    p_str = f\"{row.p_value:10.4f}\" if row.p_value is not None else \"          \"\n",
    "    print(f\"  {row.source:25s}  {row.df:4d}  {row.sum_sq:12.4f}  {row.mean_sq:12.4f}  {f_str}  {p_str}\")\n",
    "print(\"-\" * 80)\n",
    "term_rows = [r for r in anova_result.rows if r.source not in summary_sources]\n",
    "if term_rows:\n",
    "    model_ss = sum(r.sum_sq for r in term_rows)\n",
    "    print(\"\\nVariance Contributions:\")\n",
    "    print(\"(Percentages relative to Model SS, not Total SS \u2014 shows relative importance within fitted model)\")\n",
    "    for row in term_rows:\n",
    "        pct = 100 * row.sum_sq / model_ss if model_ss > 0 else 0\n",
    "        sig = (\n",
    "            \"***\" if row.p_value is not None and row.p_value < 0.001 else (\n",
    "            \"**\" if row.p_value is not None and row.p_value < 0.01 else (\n",
    "            \"*\" if row.p_value is not None and row.p_value < 0.05 else \"\"))\n",
    "        )\n",
    "        print(f\"  {row.source:25s}  {pct:6.1f}%  {sig}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae31468",
   "metadata": {},
   "source": [
    "### Note on the spurious C_B^2 term\n",
    "\n",
    "The discovered expression `y = 1.498*C_A*sqrt(C_B) + 0.002122*C_B^2` includes a\n",
    "spurious `C_B^2` term with a negligibly small coefficient (0.002). The dominant term\n",
    "`1.498*C_A*sqrt(C_B)` closely matches the true model `1.5*C_A*sqrt(C_B)`.\n",
    "\n",
    "The BIC penalty was not large enough to prefer the simpler 1-term model over the\n",
    "2-term model, because the additional term marginally reduces the residual sum of\n",
    "squares. In practice, the `C_B^2` contribution is negligible across the data range\n",
    "and can be safely dropped when interpreting the result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5917c83",
   "metadata": {},
   "source": [
    "## Discover Arrhenius temperature dependence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65da6ed1",
   "metadata": {},
   "source": [
    "True model:\n",
    "\n",
    "$$\\ln k = \\ln A - \\frac{E_a}{RT}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "859206c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T22:36:17.488087Z",
     "iopub.status.busy": "2026-02-10T22:36:17.487996Z",
     "iopub.status.idle": "2026-02-10T22:36:17.890102Z",
     "shell.execute_reply": "2026-02-10T22:36:17.889631Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "True model: ln(k) = ln(A) - Ea/(R*T)\n",
      "Or: ln(k) = 13.82 - 6.01 * (1000/T)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Discovered expression:\n",
      "  y = 13.79 - 6.006*1000/T\n",
      "  R\u00b2 = 0.9996\n",
      "\n",
      "Extracted parameters:\n",
      "  ln(A) = 13.79 (true: 13.82)\n",
      "  Ea = 49932 J/mol (true: 50000 J/mol)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "n_samples = 50\n",
    "\n",
    "# Temperature range (K)\n",
    "T = np.random.uniform(300, 500, n_samples)\n",
    "\n",
    "# Arrhenius parameters\n",
    "A = 1e6  # Pre-exponential factor\n",
    "Ea = 50000  # Activation energy (J/mol)\n",
    "R = 8.314  # Gas constant (J/mol/K)\n",
    "\n",
    "# True rate constant\n",
    "k_true = A * np.exp(-Ea / (R * T))\n",
    "# Work in log space for better fitting\n",
    "log_k = np.log(k_true) + np.random.randn(n_samples) * 0.05\n",
    "\n",
    "# Use 1/T as the feature (linearized Arrhenius)\n",
    "X = jnp.array(1000 / T).reshape(-1, 1)  # 1000/T in 1/K\n",
    "y = jnp.array(log_k)\n",
    "\n",
    "print(\"\\nTrue model: ln(k) = ln(A) - Ea/(R*T)\")\n",
    "print(f\"Or: ln(k) = {np.log(A):.2f} - {Ea/R/1000:.2f} * (1000/T)\")\n",
    "\n",
    "# Simple linear library for linearized Arrhenius\n",
    "library = BasisLibrary(n_features=1, feature_names=[\"1000/T\"]).add_constant().add_linear()\n",
    "\n",
    "model = SymbolicRegressor(\n",
    "    basis_library=library,\n",
    "    max_terms=2,\n",
    "    strategy=\"exhaustive\",\n",
    ")\n",
    "model.fit(X, y)\n",
    "\n",
    "print(\"\\nDiscovered expression:\")\n",
    "print(f\"  {model.expression_}\")\n",
    "print(f\"  R\u00b2 = {model.metrics_['r2']:.4f}\")\n",
    "\n",
    "# Extract parameters\n",
    "if \"1\" in model.selected_features_:\n",
    "    idx_const = model.selected_features_.index(\"1\")\n",
    "    ln_A = float(model.coefficients_[idx_const])\n",
    "    print(\"\\nExtracted parameters:\")\n",
    "    print(f\"  ln(A) = {ln_A:.2f} (true: {np.log(A):.2f})\")\n",
    "\n",
    "if \"1000/T\" in model.selected_features_:\n",
    "    idx_T = model.selected_features_.index(\"1000/T\")\n",
    "    slope = float(model.coefficients_[idx_T])\n",
    "    Ea_fit = -slope * R * 1000\n",
    "    print(f\"  Ea = {Ea_fit:.0f} J/mol (true: {Ea} J/mol)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "z24jhga09tm",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T22:36:17.891203Z",
     "iopub.status.busy": "2026-02-10T22:36:17.891131Z",
     "iopub.status.idle": "2026-02-10T22:36:18.055642Z",
     "shell.execute_reply": "2026-02-10T22:36:18.055080Z"
    }
   },
   "outputs": [],
   "source": [
    "# Parameter significance, diagnostics, and ANOVA\n",
    "intervals = model.coefficient_intervals(alpha=0.05)\n",
    "n_obs, k_terms = len(np.asarray(y)), len(model.selected_features_)\n",
    "df_resid = n_obs - k_terms\n",
    "\n",
    "print(\"Parameter Significance (95% CI):\")\n",
    "print(f\"  {'Term':>15s} {'Estimate':>10s} {'Std Err':>9s} {'t':>8s} {'p-value':>10s} 95% CI\")\n",
    "print(\"  \" + \"-\" * 75)\n",
    "for name, (est, lo, hi, se) in intervals.items():\n",
    "    t_val = est / se if abs(se) > 1e-15 else float(\"inf\")\n",
    "    p_val = float(2 * (1 - sp_stats.t.cdf(abs(t_val), df_resid))) if df_resid > 0 else 0.0\n",
    "    sig = \"***\" if p_val < 0.001 else (\"**\" if p_val < 0.01 else (\"*\" if p_val < 0.05 else \"\"))\n",
    "    print(f\"  {name:>15s} {est:10.4f} {se:9.4f} {t_val:8.2f} {p_val:10.2e} [{lo:.4f}, {hi:.4f}] {sig}\")\n",
    "print(\"  --- *** p<0.001, ** p<0.01, * p<0.05\")\n",
    "\n",
    "y_pred = model.predict(X)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "plot_parity(y, y_pred, ax=axes[0], title=\"Arrhenius: Parity\")\n",
    "residuals = np.array(y - y_pred)\n",
    "axes[1].scatter(np.array(y_pred), residuals, alpha=0.6, c=\"steelblue\", edgecolors=\"white\", linewidth=0.5)\n",
    "axes[1].axhline(y=0, color=\"r\", linestyle=\"--\")\n",
    "axes[1].set_xlabel(\"Predicted\")\n",
    "axes[1].set_ylabel(\"Residuals\")\n",
    "axes[1].set_title(\"Arrhenius: Residuals\")\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "anova_result = anova(model)\n",
    "summary_sources = {\"Model\", \"Residual\", \"Total\"}\n",
    "print(\"\\nANOVA Table (Arrhenius)\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"  {'Source':25s}  {'DF':>4}  {'Sum Sq':>12}  {'Mean Sq':>12}  {'F':>10}  {'p-value':>10}\")\n",
    "print(\"-\" * 80)\n",
    "for row in anova_result.rows:\n",
    "    f_str = f\"{row.f_value:10.2f}\" if row.f_value is not None else \"          \"\n",
    "    p_str = f\"{row.p_value:10.4f}\" if row.p_value is not None else \"          \"\n",
    "    print(f\"  {row.source:25s}  {row.df:4d}  {row.sum_sq:12.4f}  {row.mean_sq:12.4f}  {f_str}  {p_str}\")\n",
    "print(\"-\" * 80)\n",
    "term_rows = [r for r in anova_result.rows if r.source not in summary_sources]\n",
    "if term_rows:\n",
    "    model_ss = sum(r.sum_sq for r in term_rows)\n",
    "    print(\"\\nVariance Contributions:\")\n",
    "    print(\"(Percentages relative to Model SS, not Total SS \u2014 shows relative importance within fitted model)\")\n",
    "    for row in term_rows:\n",
    "        pct = 100 * row.sum_sq / model_ss if model_ss > 0 else 0\n",
    "        sig = (\n",
    "            \"***\" if row.p_value is not None and row.p_value < 0.001 else (\n",
    "            \"**\" if row.p_value is not None and row.p_value < 0.01 else (\n",
    "            \"*\" if row.p_value is not None and row.p_value < 0.05 else \"\"))\n",
    "        )\n",
    "        print(f\"  {row.source:25s}  {pct:6.1f}%  {sig}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928cbc8b",
   "metadata": {},
   "source": [
    "## Discover competitive adsorption kinetics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bac661d",
   "metadata": {},
   "source": [
    "True model:\n",
    "\n",
    "$$r = \\frac{3.0\\,C_A\\,C_B}{1 + 0.8\\,C_A + 1.5\\,C_B}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5da7bae5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T22:36:18.056866Z",
     "iopub.status.busy": "2026-02-10T22:36:18.056768Z",
     "iopub.status.idle": "2026-02-10T22:36:18.832722Z",
     "shell.execute_reply": "2026-02-10T22:36:18.832284Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "True model: r = 3.0*C_A*C_B / (1 + 0.8*C_A + 1.5*C_B)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Discovered expression:\n",
      "  y = 3.393*C_A*C_B/(1+C_A+C_B) - 0.4771*C_A*C_B/(1+C_A) + 0.02056*C_A^2\n",
      "  R\u00b2 = 0.9972\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "n_samples = 150\n",
    "\n",
    "C_A = np.random.uniform(0.1, 2.0, n_samples)\n",
    "C_B = np.random.uniform(0.1, 2.0, n_samples)\n",
    "\n",
    "# Kinetic parameters\n",
    "k = 3.0\n",
    "K_A = 0.8\n",
    "K_B = 1.5\n",
    "\n",
    "r_true = k * C_A * C_B / (1 + K_A * C_A + K_B * C_B)\n",
    "r = r_true + np.random.randn(n_samples) * 0.03\n",
    "\n",
    "X = jnp.column_stack([C_A, C_B])\n",
    "y = jnp.array(r)\n",
    "\n",
    "print(\"\\nTrue model: r = 3.0*C_A*C_B / (1 + 0.8*C_A + 1.5*C_B)\")\n",
    "\n",
    "# Build comprehensive library\n",
    "library = (\n",
    "    BasisLibrary(n_features=2, feature_names=[\"C_A\", \"C_B\"])\n",
    "    .add_constant()\n",
    "    .add_linear()\n",
    "    .add_polynomials(max_degree=2)\n",
    "    .add_interactions(max_order=2)\n",
    "    .add_ratios()\n",
    ")\n",
    "\n",
    "# Add custom rational functions\n",
    "library.add_custom(\n",
    "    name=\"C_A*C_B/(1+C_A)\",\n",
    "    func=lambda X: X[:, 0] * X[:, 1] / (1 + X[:, 0]),\n",
    "    complexity=3,\n",
    ")\n",
    "library.add_custom(\n",
    "    name=\"C_A*C_B/(1+C_B)\",\n",
    "    func=lambda X: X[:, 0] * X[:, 1] / (1 + X[:, 1]),\n",
    "    complexity=3,\n",
    ")\n",
    "library.add_custom(\n",
    "    name=\"C_A*C_B/(1+C_A+C_B)\",\n",
    "    func=lambda X: X[:, 0] * X[:, 1] / (1 + X[:, 0] + X[:, 1]),\n",
    "    complexity=4,\n",
    ")\n",
    "\n",
    "model = SymbolicRegressor(\n",
    "    basis_library=library,\n",
    "    max_terms=5,\n",
    "    strategy=\"greedy_forward\",\n",
    ")\n",
    "model.fit(X, y)\n",
    "\n",
    "print(\"\\nDiscovered expression:\")\n",
    "print(f\"  {model.expression_}\")\n",
    "print(f\"  R\u00b2 = {model.metrics_['r2']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "myeg6ftu4lk",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T22:36:18.833842Z",
     "iopub.status.busy": "2026-02-10T22:36:18.833776Z",
     "iopub.status.idle": "2026-02-10T22:36:19.186812Z",
     "shell.execute_reply": "2026-02-10T22:36:19.186504Z"
    }
   },
   "outputs": [],
   "source": [
    "# Parameter significance, diagnostics, and ANOVA\n",
    "intervals = model.coefficient_intervals(alpha=0.05)\n",
    "n_obs, k_terms = len(np.asarray(y)), len(model.selected_features_)\n",
    "df_resid = n_obs - k_terms\n",
    "\n",
    "print(\"Parameter Significance (95% CI):\")\n",
    "print(f\"  {'Term':>15s} {'Estimate':>10s} {'Std Err':>9s} {'t':>8s} {'p-value':>10s} 95% CI\")\n",
    "print(\"  \" + \"-\" * 75)\n",
    "for name, (est, lo, hi, se) in intervals.items():\n",
    "    t_val = est / se if abs(se) > 1e-15 else float(\"inf\")\n",
    "    p_val = float(2 * (1 - sp_stats.t.cdf(abs(t_val), df_resid))) if df_resid > 0 else 0.0\n",
    "    sig = \"***\" if p_val < 0.001 else (\"**\" if p_val < 0.01 else (\"*\" if p_val < 0.05 else \"\"))\n",
    "    print(f\"  {name:>15s} {est:10.4f} {se:9.4f} {t_val:8.2f} {p_val:10.2e} [{lo:.4f}, {hi:.4f}] {sig}\")\n",
    "print(\"  --- *** p<0.001, ** p<0.01, * p<0.05\")\n",
    "\n",
    "y_pred = model.predict(X)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "plot_parity(y, y_pred, ax=axes[0], title=\"Competitive Adsorption: Parity\")\n",
    "residuals = np.array(y - y_pred)\n",
    "axes[1].scatter(np.array(y_pred), residuals, alpha=0.6, c=\"steelblue\", edgecolors=\"white\", linewidth=0.5)\n",
    "axes[1].axhline(y=0, color=\"r\", linestyle=\"--\")\n",
    "axes[1].set_xlabel(\"Predicted\")\n",
    "axes[1].set_ylabel(\"Residuals\")\n",
    "axes[1].set_title(\"Competitive Adsorption: Residuals\")\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "anova_result = anova(model)\n",
    "summary_sources = {\"Model\", \"Residual\", \"Total\"}\n",
    "print(\"\\nANOVA Table (Competitive Adsorption)\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"  {'Source':25s}  {'DF':>4}  {'Sum Sq':>12}  {'Mean Sq':>12}  {'F':>10}  {'p-value':>10}\")\n",
    "print(\"-\" * 80)\n",
    "for row in anova_result.rows:\n",
    "    f_str = f\"{row.f_value:10.2f}\" if row.f_value is not None else \"          \"\n",
    "    p_str = f\"{row.p_value:10.4f}\" if row.p_value is not None else \"          \"\n",
    "    print(f\"  {row.source:25s}  {row.df:4d}  {row.sum_sq:12.4f}  {row.mean_sq:12.4f}  {f_str}  {p_str}\")\n",
    "print(\"-\" * 80)\n",
    "term_rows = [r for r in anova_result.rows if r.source not in summary_sources]\n",
    "if term_rows:\n",
    "    model_ss = sum(r.sum_sq for r in term_rows)\n",
    "    print(\"\\nVariance Contributions:\")\n",
    "    print(\"(Percentages relative to Model SS, not Total SS \u2014 shows relative importance within fitted model)\")\n",
    "    for row in term_rows:\n",
    "        pct = 100 * row.sum_sq / model_ss if model_ss > 0 else 0\n",
    "        sig = (\n",
    "            \"***\" if row.p_value is not None and row.p_value < 0.001 else (\n",
    "            \"**\" if row.p_value is not None and row.p_value < 0.01 else (\n",
    "            \"*\" if row.p_value is not None and row.p_value < 0.05 else \"\"))\n",
    "        )\n",
    "        print(f\"  {row.source:25s}  {pct:6.1f}%  {sig}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}