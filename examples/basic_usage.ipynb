{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e568ba78",
   "metadata": {},
   "source": [
    "# Basic Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a0a741",
   "metadata": {},
   "source": [
    "Basic Usage Example for JAXSR.\n",
    "\n",
    "Demonstrates the core functionality of JAXSR for discovering\n",
    "algebraic expressions from data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41d13b80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T22:36:28.096848Z",
     "iopub.status.busy": "2026-02-10T22:36:28.096765Z",
     "iopub.status.idle": "2026-02-10T22:36:28.519780Z",
     "shell.execute_reply": "2026-02-10T22:36:28.519466Z"
    }
   },
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "from jaxsr import BasisLibrary, SymbolicRegressor, fit_symbolic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e622c3b",
   "metadata": {},
   "source": [
    "## Discover a polynomial expression.\n",
    "\n",
    "$$y = 2.5\\,x_0 + 1.2\\,x_0\\,x_1 - 0.8\\,x_1^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96b804bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T22:36:28.521195Z",
     "iopub.status.busy": "2026-02-10T22:36:28.521099Z",
     "iopub.status.idle": "2026-02-10T22:36:30.357597Z",
     "shell.execute_reply": "2026-02-10T22:36:30.357162Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "True model: y = 2.5*x0 + 1.2*x0*x1 - 0.8*x1^2\n",
      "Data: 200 samples, 2 features, noise std=0.1\n",
      "\n",
      "Basis library: 8 candidate functions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Discovered expression:\n",
      "  y = - 0.7996*x1^2 + 2.502*x0 + 1.198*x0*x1 - 0.002767*x0^2\n",
      "\n",
      "Metrics:\n",
      "  R\u00b2 score: 0.999827\n",
      "  MSE: 0.009535\n",
      "  BIC: -341.78\n",
      "  Complexity: 7\n"
     ]
    }
   ],
   "source": [
    "# Generate synthetic data: y = 2.5*x0 + 1.2*x0*x1 - 0.8*x1^2 + noise\n",
    "np.random.seed(42)\n",
    "n_samples = 200\n",
    "X = np.random.randn(n_samples, 2) * 2\n",
    "y = 2.5 * X[:, 0] + 1.2 * X[:, 0] * X[:, 1] - 0.8 * X[:, 1] ** 2\n",
    "y += np.random.randn(n_samples) * 0.1\n",
    "\n",
    "X_jax = jnp.array(X)\n",
    "y_jax = jnp.array(y)\n",
    "\n",
    "print(\"\\nTrue model: y = 2.5*x0 + 1.2*x0*x1 - 0.8*x1^2\")\n",
    "print(f\"Data: {n_samples} samples, 2 features, noise std=0.1\")\n",
    "\n",
    "# Build basis library\n",
    "library = (\n",
    "    BasisLibrary(n_features=2, feature_names=[\"x0\", \"x1\"])\n",
    "    .add_constant()\n",
    "    .add_linear()\n",
    "    .add_polynomials(max_degree=3)\n",
    "    .add_interactions(max_order=2)\n",
    ")\n",
    "\n",
    "print(f\"\\nBasis library: {len(library)} candidate functions\")\n",
    "\n",
    "# Fit model\n",
    "model = SymbolicRegressor(\n",
    "    basis_library=library,\n",
    "    max_terms=5,\n",
    "    strategy=\"greedy_forward\",\n",
    "    information_criterion=\"bic\",\n",
    ")\n",
    "model.fit(X_jax, y_jax)\n",
    "\n",
    "# Results\n",
    "print(\"\\nDiscovered expression:\")\n",
    "print(f\"  {model.expression_}\")\n",
    "print(\"\\nMetrics:\")\n",
    "print(f\"  R\u00b2 score: {model.score(X_jax, y_jax):.6f}\")\n",
    "print(f\"  MSE: {model.metrics_['mse']:.6f}\")\n",
    "print(f\"  BIC: {model.metrics_['bic']:.2f}\")\n",
    "print(f\"  Complexity: {model.complexity_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "as09oo3i6m",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T22:36:30.358842Z",
     "iopub.status.busy": "2026-02-10T22:36:30.358775Z",
     "iopub.status.idle": "2026-02-10T22:36:30.974518Z",
     "shell.execute_reply": "2026-02-10T22:36:30.974115Z"
    }
   },
   "outputs": [],
   "source": [
    "# Parameter significance, diagnostics, and ANOVA",
    "import matplotlib.pyplot as plt",
    "from scipy import stats as sp_stats",
    "from jaxsr import anova",
    "from jaxsr.plotting import plot_parity",
    "",
    "intervals = model.coefficient_intervals(alpha=0.05)",
    "n_obs, k_terms = len(np.asarray(y_jax)), len(model.selected_features_)",
    "df_resid = n_obs - k_terms",
    "",
    "print(\"Parameter Significance (95% CI):\")",
    "print(f\"  {'Term':>15s} {'Estimate':>10s} {'Std Err':>9s} {'t':>8s} {'p-value':>10s} 95% CI\")",
    "print(\"  \" + \"-\" * 75)",
    "for name, (est, lo, hi, se) in intervals.items():",
    "    t_val = est / se if abs(se) > 1e-15 else float(\"inf\")",
    "    p_val = float(2 * (1 - sp_stats.t.cdf(abs(t_val), df_resid))) if df_resid > 0 else 0.0",
    "    sig = \"***\" if p_val < 0.001 else (\"**\" if p_val < 0.01 else (\"*\" if p_val < 0.05 else \"\"))",
    "    print(f\"  {name:>15s} {est:10.4f} {se:9.4f} {t_val:8.2f} {p_val:10.2e} [{lo:.4f}, {hi:.4f}] {sig}\")",
    "print(\"  --- *** p<0.001, ** p<0.01, * p<0.05\")",
    "",
    "y_pred = model.predict(X_jax)",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))",
    "plot_parity(y_jax, y_pred, ax=axes[0], title=\"Polynomial: Parity\")",
    "residuals = np.array(y_jax - y_pred)",
    "axes[1].scatter(np.array(y_pred), residuals, alpha=0.6, c=\"steelblue\", edgecolors=\"white\", linewidth=0.5)",
    "axes[1].axhline(y=0, color=\"r\", linestyle=\"--\")",
    "axes[1].set_xlabel(\"Predicted\")",
    "axes[1].set_ylabel(\"Residuals\")",
    "axes[1].set_title(\"Polynomial: Residuals\")",
    "axes[1].grid(True, alpha=0.3)",
    "plt.tight_layout()",
    "plt.show()",
    "",
    "anova_result = anova(model)",
    "summary_sources = {\"Model\", \"Residual\", \"Total\"}",
    "print(\"\\nANOVA Table (Polynomial)\")",
    "print(\"=\" * 80)",
    "print(f\"  {'Source':25s}  {'DF':>4}  {'Sum Sq':>12}  {'Mean Sq':>12}  {'F':>10}  {'p-value':>10}\")",
    "print(\"-\" * 80)",
    "for row in anova_result.rows:",
    "    f_str = f\"{row.f_value:10.2f}\" if row.f_value is not None else \"          \"",
    "    p_str = f\"{row.p_value:10.4f}\" if row.p_value is not None else \"          \"",
    "    print(f\"  {row.source:25s}  {row.df:4d}  {row.sum_sq:12.4f}  {row.mean_sq:12.4f}  {f_str}  {p_str}\")",
    "print(\"-\" * 80)",
    "term_rows = [r for r in anova_result.rows if r.source not in summary_sources]",
    "if term_rows:",
    "    model_ss = sum(r.sum_sq for r in term_rows)",
    "    print(\"\\nVariance Contributions:\")",
    "print(\"(Percentages relative to Model SS, not Total SS \u2014 shows relative importance within fitted model)\")",
    "    for row in term_rows:",
    "        pct = 100 * row.sum_sq / model_ss if model_ss > 0 else 0",
    "        sig = (",
    "            \"***\" if row.p_value is not None and row.p_value < 0.001 else (",
    "            \"**\" if row.p_value is not None and row.p_value < 0.01 else (",
    "            \"*\" if row.p_value is not None and row.p_value < 0.05 else \"\"))",
    "        )",
    "        print(f\"  {row.source:25s}  {pct:6.1f}%  {sig}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff173d50",
   "metadata": {},
   "source": [
    "## Discover an expression with transcendental functions.\n",
    "\n",
    "$$y = e^{-0.5\\,x} + \\ln(x + 1)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8157b48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T22:36:30.975848Z",
     "iopub.status.busy": "2026-02-10T22:36:30.975722Z",
     "iopub.status.idle": "2026-02-10T22:36:31.738298Z",
     "shell.execute_reply": "2026-02-10T22:36:31.737884Z"
    }
   },
   "outputs": [],
   "source": "# Generate data: y = exp(-0.5*x) + log(x+1)\nnp.random.seed(42)\nn_samples = 150\nX = np.random.uniform(0.1, 3.0, (n_samples, 1))\ny = np.exp(-0.5 * X[:, 0]) + np.log(X[:, 0] + 1)\ny += np.random.randn(n_samples) * 0.02\n\nX_jax = jnp.array(X)\ny_jax = jnp.array(y)\n\nprint(\"\\nTrue model: y = exp(-0.5*x) + log(x+1)\")\nprint(f\"Data: {n_samples} samples, 1 feature\")\n\n# Build library with transcendental functions\nlibrary = (\n    BasisLibrary(n_features=1, feature_names=[\"x\"])\n    .add_constant()\n    .add_linear()\n    .add_polynomials(max_degree=3)\n    .add_transcendental([\"log\", \"exp\", \"sqrt\"])\n)\n\nprint(f\"\\nBasis library: {len(library)} candidate functions\")\n\nmodel = SymbolicRegressor(\n    basis_library=library,\n    max_terms=6,\n    strategy=\"greedy_forward\",\n)\nmodel.fit(X_jax, y_jax)\n\nprint(\"\\nDiscovered expression:\")\nprint(f\"  {model.expression_}\")\nprint(f\"  R\u00b2 score: {model.score(X_jax, y_jax):.6f}\")\n\n# Explain the approximation\nprint(\"\\nNote: The discovered expression approximates the true model using\")\nprint(\"different basis functions. This is expected \u2014 the library contains\")\nprint(\"exp(x) and log(x), but NOT exp(-0.5*x) or log(x+1) as single terms.\")\nprint(\"JAXSR finds the best linear combination of available basis functions.\")\nprint(\"To recover the exact form, you would need parametric basis functions\")\nprint(\"(see the Langmuir isotherm and model comparison examples).\")"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "t2vcrkzfyr",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T22:36:31.739689Z",
     "iopub.status.busy": "2026-02-10T22:36:31.739608Z",
     "iopub.status.idle": "2026-02-10T22:36:32.125980Z",
     "shell.execute_reply": "2026-02-10T22:36:32.125574Z"
    }
   },
   "outputs": [],
   "source": [
    "# Parameter significance, diagnostics, and ANOVA",
    "intervals = model.coefficient_intervals(alpha=0.05)",
    "n_obs, k_terms = len(np.asarray(y_jax)), len(model.selected_features_)",
    "df_resid = n_obs - k_terms",
    "",
    "print(\"Parameter Significance (95% CI):\")",
    "print(f\"  {'Term':>15s} {'Estimate':>10s} {'Std Err':>9s} {'t':>8s} {'p-value':>10s} 95% CI\")",
    "print(\"  \" + \"-\" * 75)",
    "for name, (est, lo, hi, se) in intervals.items():",
    "    t_val = est / se if abs(se) > 1e-15 else float(\"inf\")",
    "    p_val = float(2 * (1 - sp_stats.t.cdf(abs(t_val), df_resid))) if df_resid > 0 else 0.0",
    "    sig = \"***\" if p_val < 0.001 else (\"**\" if p_val < 0.01 else (\"*\" if p_val < 0.05 else \"\"))",
    "    print(f\"  {name:>15s} {est:10.4f} {se:9.4f} {t_val:8.2f} {p_val:10.2e} [{lo:.4f}, {hi:.4f}] {sig}\")",
    "print(\"  --- *** p<0.001, ** p<0.01, * p<0.05\")",
    "",
    "y_pred = model.predict(X_jax)",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))",
    "plot_parity(y_jax, y_pred, ax=axes[0], title=\"Transcendental: Parity\")",
    "residuals = np.array(y_jax - y_pred)",
    "axes[1].scatter(np.array(y_pred), residuals, alpha=0.6, c=\"steelblue\", edgecolors=\"white\", linewidth=0.5)",
    "axes[1].axhline(y=0, color=\"r\", linestyle=\"--\")",
    "axes[1].set_xlabel(\"Predicted\")",
    "axes[1].set_ylabel(\"Residuals\")",
    "axes[1].set_title(\"Transcendental: Residuals\")",
    "axes[1].grid(True, alpha=0.3)",
    "plt.tight_layout()",
    "plt.show()",
    "",
    "anova_result = anova(model)",
    "summary_sources = {\"Model\", \"Residual\", \"Total\"}",
    "print(\"\\nANOVA Table (Transcendental)\")",
    "print(\"=\" * 80)",
    "print(f\"  {'Source':25s}  {'DF':>4}  {'Sum Sq':>12}  {'Mean Sq':>12}  {'F':>10}  {'p-value':>10}\")",
    "print(\"-\" * 80)",
    "for row in anova_result.rows:",
    "    f_str = f\"{row.f_value:10.2f}\" if row.f_value is not None else \"          \"",
    "    p_str = f\"{row.p_value:10.4f}\" if row.p_value is not None else \"          \"",
    "    print(f\"  {row.source:25s}  {row.df:4d}  {row.sum_sq:12.4f}  {row.mean_sq:12.4f}  {f_str}  {p_str}\")",
    "print(\"-\" * 80)",
    "term_rows = [r for r in anova_result.rows if r.source not in summary_sources]",
    "if term_rows:",
    "    model_ss = sum(r.sum_sq for r in term_rows)",
    "    print(\"\\nVariance Contributions:\")",
    "print(\"(Percentages relative to Model SS, not Total SS \u2014 shows relative importance within fitted model)\")",
    "    for row in term_rows:",
    "        pct = 100 * row.sum_sq / model_ss if model_ss > 0 else 0",
    "        sig = (",
    "            \"***\" if row.p_value is not None and row.p_value < 0.001 else (",
    "            \"**\" if row.p_value is not None and row.p_value < 0.01 else (",
    "            \"*\" if row.p_value is not None and row.p_value < 0.05 else \"\"))",
    "        )",
    "        print(f\"  {row.source:25s}  {pct:6.1f}%  {sig}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14c517b",
   "metadata": {},
   "source": [
    "## Use the fit_symbolic convenience function.\n",
    "\n",
    "$$y = 3\\,a^2 - 2\\,b + 1$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1238a5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T22:36:32.127370Z",
     "iopub.status.busy": "2026-02-10T22:36:32.127283Z",
     "iopub.status.idle": "2026-02-10T22:36:32.964579Z",
     "shell.execute_reply": "2026-02-10T22:36:32.964176Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "True model: y = 3*a^2 - 2*b + 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jkitchin/Dropbox/projects/jaxsr/src/jaxsr/regressor.py:1234: UserWarning: Removing 4 basis functions with non-finite values\n",
      "  return model.fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Discovered: y = 3*a^2 - 2.008*b + 1.004\n",
      "R\u00b2 = 0.9998\n"
     ]
    }
   ],
   "source": [
    "# Generate data\n",
    "np.random.seed(42)\n",
    "X = np.random.randn(100, 2)\n",
    "y = 3.0 * X[:, 0] ** 2 - 2.0 * X[:, 1] + 1.0\n",
    "y += np.random.randn(100) * 0.05\n",
    "\n",
    "print(\"\\nTrue model: y = 3*a^2 - 2*b + 1\")\n",
    "\n",
    "# Quick fit\n",
    "model = fit_symbolic(\n",
    "    jnp.array(X),\n",
    "    jnp.array(y),\n",
    "    feature_names=[\"a\", \"b\"],\n",
    "    max_terms=5,\n",
    "    max_poly_degree=3,\n",
    ")\n",
    "\n",
    "print(f\"\\nDiscovered: {model.expression_}\")\n",
    "print(f\"R\u00b2 = {model.score(jnp.array(X), jnp.array(y)):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7bjqyb7qos",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T22:36:32.965755Z",
     "iopub.status.busy": "2026-02-10T22:36:32.965681Z",
     "iopub.status.idle": "2026-02-10T22:36:33.166074Z",
     "shell.execute_reply": "2026-02-10T22:36:33.165746Z"
    }
   },
   "outputs": [],
   "source": [
    "# Parameter significance, diagnostics, and ANOVA",
    "intervals = model.coefficient_intervals(alpha=0.05)",
    "X_fit, y_fit = jnp.array(X), jnp.array(y)",
    "n_obs, k_terms = len(np.asarray(y_fit)), len(model.selected_features_)",
    "df_resid = n_obs - k_terms",
    "",
    "print(\"Parameter Significance (95% CI):\")",
    "print(f\"  {'Term':>15s} {'Estimate':>10s} {'Std Err':>9s} {'t':>8s} {'p-value':>10s} 95% CI\")",
    "print(\"  \" + \"-\" * 75)",
    "for name, (est, lo, hi, se) in intervals.items():",
    "    t_val = est / se if abs(se) > 1e-15 else float(\"inf\")",
    "    p_val = float(2 * (1 - sp_stats.t.cdf(abs(t_val), df_resid))) if df_resid > 0 else 0.0",
    "    sig = \"***\" if p_val < 0.001 else (\"**\" if p_val < 0.01 else (\"*\" if p_val < 0.05 else \"\"))",
    "    print(f\"  {name:>15s} {est:10.4f} {se:9.4f} {t_val:8.2f} {p_val:10.2e} [{lo:.4f}, {hi:.4f}] {sig}\")",
    "print(\"  --- *** p<0.001, ** p<0.01, * p<0.05\")",
    "",
    "y_pred = model.predict(X_fit)",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))",
    "plot_parity(y_fit, y_pred, ax=axes[0], title=\"fit_symbolic: Parity\")",
    "residuals = np.array(y_fit - y_pred)",
    "axes[1].scatter(np.array(y_pred), residuals, alpha=0.6, c=\"steelblue\", edgecolors=\"white\", linewidth=0.5)",
    "axes[1].axhline(y=0, color=\"r\", linestyle=\"--\")",
    "axes[1].set_xlabel(\"Predicted\")",
    "axes[1].set_ylabel(\"Residuals\")",
    "axes[1].set_title(\"fit_symbolic: Residuals\")",
    "axes[1].grid(True, alpha=0.3)",
    "plt.tight_layout()",
    "plt.show()",
    "",
    "anova_result = anova(model)",
    "summary_sources = {\"Model\", \"Residual\", \"Total\"}",
    "print(\"\\nANOVA Table (fit_symbolic)\")",
    "print(\"=\" * 80)",
    "print(f\"  {'Source':25s}  {'DF':>4}  {'Sum Sq':>12}  {'Mean Sq':>12}  {'F':>10}  {'p-value':>10}\")",
    "print(\"-\" * 80)",
    "for row in anova_result.rows:",
    "    f_str = f\"{row.f_value:10.2f}\" if row.f_value is not None else \"          \"",
    "    p_str = f\"{row.p_value:10.4f}\" if row.p_value is not None else \"          \"",
    "    print(f\"  {row.source:25s}  {row.df:4d}  {row.sum_sq:12.4f}  {row.mean_sq:12.4f}  {f_str}  {p_str}\")",
    "print(\"-\" * 80)",
    "term_rows = [r for r in anova_result.rows if r.source not in summary_sources]",
    "if term_rows:",
    "    model_ss = sum(r.sum_sq for r in term_rows)",
    "    print(\"\\nVariance Contributions:\")",
    "print(\"(Percentages relative to Model SS, not Total SS \u2014 shows relative importance within fitted model)\")",
    "    for row in term_rows:",
    "        pct = 100 * row.sum_sq / model_ss if model_ss > 0 else 0",
    "        sig = (",
    "            \"***\" if row.p_value is not None and row.p_value < 0.001 else (",
    "            \"**\" if row.p_value is not None and row.p_value < 0.01 else (",
    "            \"*\" if row.p_value is not None and row.p_value < 0.05 else \"\"))",
    "        )",
    "        print(f\"  {row.source:25s}  {pct:6.1f}%  {sig}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecaf3ce",
   "metadata": {},
   "source": [
    "## Explore the Pareto front of complexity vs accuracy.\n",
    "\n",
    "$$y = 2\\,x + 1.5\\,y^2 - 0.5\\,x\\,y$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8c48198",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T22:36:33.167561Z",
     "iopub.status.busy": "2026-02-10T22:36:33.167482Z",
     "iopub.status.idle": "2026-02-10T22:36:33.400392Z",
     "shell.execute_reply": "2026-02-10T22:36:33.399703Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pareto Front (Complexity vs MSE):\n",
      "  Complexity  2 | MSE 4.223643\n",
      "    y = 1.63*y^2\n",
      "\n",
      "  Complexity  3 | MSE 0.214977\n",
      "    y = 1.496*y^2 + 2.091*x\n",
      "\n",
      "  Complexity  5 | MSE 0.008936\n",
      "    y = 1.497*y^2 + 2.002*x - 0.5041*x*y\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate data\n",
    "np.random.seed(42)\n",
    "X = np.random.randn(150, 2)\n",
    "y = 2.0 * X[:, 0] + 1.5 * X[:, 1] ** 2 - 0.5 * X[:, 0] * X[:, 1]\n",
    "y += np.random.randn(150) * 0.1\n",
    "\n",
    "X_jax = jnp.array(X)\n",
    "y_jax = jnp.array(y)\n",
    "\n",
    "library = (\n",
    "    BasisLibrary(n_features=2, feature_names=[\"x\", \"y\"])\n",
    "    .add_constant()\n",
    "    .add_linear()\n",
    "    .add_polynomials(max_degree=3)\n",
    "    .add_interactions(max_order=2)\n",
    ")\n",
    "\n",
    "model = SymbolicRegressor(\n",
    "    basis_library=library,\n",
    "    max_terms=6,\n",
    "    strategy=\"greedy_forward\",\n",
    ")\n",
    "model.fit(X_jax, y_jax)\n",
    "\n",
    "print(\"\\nPareto Front (Complexity vs MSE):\")\n",
    "for result in model.pareto_front_:\n",
    "    print(f\"  Complexity {result.complexity:2d} | MSE {result.mse:.6f}\")\n",
    "    print(f\"    {result.expression()}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "biw2ger8fxi",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T22:36:33.401548Z",
     "iopub.status.busy": "2026-02-10T22:36:33.401474Z",
     "iopub.status.idle": "2026-02-10T22:36:33.475800Z",
     "shell.execute_reply": "2026-02-10T22:36:33.475459Z"
    }
   },
   "outputs": [],
   "source": [
    "# Parameter significance, diagnostics, and ANOVA",
    "intervals = model.coefficient_intervals(alpha=0.05)",
    "n_obs, k_terms = len(np.asarray(y_jax)), len(model.selected_features_)",
    "df_resid = n_obs - k_terms",
    "",
    "print(\"Parameter Significance (95% CI):\")",
    "print(f\"  {'Term':>15s} {'Estimate':>10s} {'Std Err':>9s} {'t':>8s} {'p-value':>10s} 95% CI\")",
    "print(\"  \" + \"-\" * 75)",
    "for name, (est, lo, hi, se) in intervals.items():",
    "    t_val = est / se if abs(se) > 1e-15 else float(\"inf\")",
    "    p_val = float(2 * (1 - sp_stats.t.cdf(abs(t_val), df_resid))) if df_resid > 0 else 0.0",
    "    sig = \"***\" if p_val < 0.001 else (\"**\" if p_val < 0.01 else (\"*\" if p_val < 0.05 else \"\"))",
    "    print(f\"  {name:>15s} {est:10.4f} {se:9.4f} {t_val:8.2f} {p_val:10.2e} [{lo:.4f}, {hi:.4f}] {sig}\")",
    "print(\"  --- *** p<0.001, ** p<0.01, * p<0.05\")",
    "",
    "y_pred = model.predict(X_jax)",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))",
    "plot_parity(y_jax, y_pred, ax=axes[0], title=\"Pareto: Parity\")",
    "residuals = np.array(y_jax - y_pred)",
    "axes[1].scatter(np.array(y_pred), residuals, alpha=0.6, c=\"steelblue\", edgecolors=\"white\", linewidth=0.5)",
    "axes[1].axhline(y=0, color=\"r\", linestyle=\"--\")",
    "axes[1].set_xlabel(\"Predicted\")",
    "axes[1].set_ylabel(\"Residuals\")",
    "axes[1].set_title(\"Pareto: Residuals\")",
    "axes[1].grid(True, alpha=0.3)",
    "plt.tight_layout()",
    "plt.show()",
    "",
    "anova_result = anova(model)",
    "summary_sources = {\"Model\", \"Residual\", \"Total\"}",
    "print(\"\\nANOVA Table (Pareto)\")",
    "print(\"=\" * 80)",
    "print(f\"  {'Source':25s}  {'DF':>4}  {'Sum Sq':>12}  {'Mean Sq':>12}  {'F':>10}  {'p-value':>10}\")",
    "print(\"-\" * 80)",
    "for row in anova_result.rows:",
    "    f_str = f\"{row.f_value:10.2f}\" if row.f_value is not None else \"          \"",
    "    p_str = f\"{row.p_value:10.4f}\" if row.p_value is not None else \"          \"",
    "    print(f\"  {row.source:25s}  {row.df:4d}  {row.sum_sq:12.4f}  {row.mean_sq:12.4f}  {f_str}  {p_str}\")",
    "print(\"-\" * 80)",
    "term_rows = [r for r in anova_result.rows if r.source not in summary_sources]",
    "if term_rows:",
    "    model_ss = sum(r.sum_sq for r in term_rows)",
    "    print(\"\\nVariance Contributions:\")",
    "print(\"(Percentages relative to Model SS, not Total SS \u2014 shows relative importance within fitted model)\")",
    "    for row in term_rows:",
    "        pct = 100 * row.sum_sq / model_ss if model_ss > 0 else 0",
    "        sig = (",
    "            \"***\" if row.p_value is not None and row.p_value < 0.001 else (",
    "            \"**\" if row.p_value is not None and row.p_value < 0.01 else (",
    "            \"*\" if row.p_value is not None and row.p_value < 0.05 else \"\"))",
    "        )",
    "        print(f\"  {row.source:25s}  {pct:6.1f}%  {sig}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3078fe",
   "metadata": {},
   "source": [
    "## Demonstrate model export capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71cdb3fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T22:36:33.476932Z",
     "iopub.status.busy": "2026-02-10T22:36:33.476868Z",
     "iopub.status.idle": "2026-02-10T22:36:33.718995Z",
     "shell.execute_reply": "2026-02-10T22:36:33.718453Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Expression: y = 2*a + b^2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jkitchin/Dropbox/projects/jaxsr/src/jaxsr/regressor.py:1234: UserWarning: Removing 4 basis functions with non-finite values\n",
      "  return model.fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SymPy: 1.99999964237213*a + 1.0*b**2.0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LaTeX: 1.99999964237213 a + 1.0 b^{2.0}\n",
      "\n",
      "Pure NumPy predictions:\n",
      "  X = [[1.0, 2.0], [3.0, 4.0]]\n",
      "  y_pred = [5.999999642372131, 21.999998927116394]\n"
     ]
    }
   ],
   "source": [
    "# Generate and fit\n",
    "np.random.seed(42)\n",
    "X = np.random.randn(100, 2)\n",
    "y = 2.0 * X[:, 0] + X[:, 1] ** 2\n",
    "\n",
    "model = fit_symbolic(\n",
    "    jnp.array(X),\n",
    "    jnp.array(y),\n",
    "    feature_names=[\"a\", \"b\"],\n",
    "    max_terms=4,\n",
    ")\n",
    "\n",
    "# Human-readable expression\n",
    "print(f\"\\nExpression: {model.expression_}\")\n",
    "\n",
    "# SymPy export\n",
    "try:\n",
    "    sympy_expr = model.to_sympy()\n",
    "    print(f\"SymPy: {sympy_expr}\")\n",
    "\n",
    "    # LaTeX\n",
    "    latex = model.to_latex()\n",
    "    print(f\"LaTeX: {latex}\")\n",
    "except ImportError:\n",
    "    print(\"(SymPy not available for symbolic export)\")\n",
    "\n",
    "# Pure Python callable\n",
    "predict_fn = model.to_callable()\n",
    "X_test = np.array([[1.0, 2.0], [3.0, 4.0]])\n",
    "y_pred = predict_fn(X_test)\n",
    "print(\"\\nPure NumPy predictions:\")\n",
    "print(f\"  X = {X_test.tolist()}\")\n",
    "print(f\"  y_pred = {y_pred.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d959a125",
   "metadata": {},
   "source": [
    "## Demonstrate uncertainty quantification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d83cc8e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T22:36:33.720386Z",
     "iopub.status.busy": "2026-02-10T22:36:33.720263Z",
     "iopub.status.idle": "2026-02-10T22:36:34.473582Z",
     "shell.execute_reply": "2026-02-10T22:36:34.473172Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "True model: y = 2*x + 1 (noise std = 0.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discovered: y = 1.954*x + 1.108\n",
      "Estimated noise std: 0.4536 (true: 0.5)\n",
      "\n",
      "95% coefficient intervals:\n",
      "  x: 1.9540 [1.8932, 2.0148]\n",
      "  1: 1.1075 [0.9386, 1.2765]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction vs confidence intervals:\n",
      "  x=1.0: pred=[2.15, 3.97], conf=[2.94, 3.18]\n",
      "  x=2.5: pred=[5.09, 6.90], conf=[5.90, 6.08]\n",
      "  x=4.0: pred=[8.01, 9.83], conf=[8.79, 9.06]\n",
      "\n",
      "Conformal 95% intervals (Jackknife+):\n",
      "  x=1.0: [2.07, 4.05]\n",
      "  x=2.5: [5.00, 6.98]\n",
      "  x=4.0: [7.94, 9.91]\n"
     ]
    }
   ],
   "source": [
    "# Generate data with known noise level\n",
    "np.random.seed(42)\n",
    "n_samples = 100\n",
    "X = np.random.uniform(0, 5, (n_samples, 1))\n",
    "y_true = 2.0 * X[:, 0] + 1.0\n",
    "y = y_true + np.random.randn(n_samples) * 0.5\n",
    "\n",
    "X_jax = jnp.array(X)\n",
    "y_jax = jnp.array(y)\n",
    "\n",
    "print(\"\\nTrue model: y = 2*x + 1 (noise std = 0.5)\")\n",
    "\n",
    "# Fit model\n",
    "library = (\n",
    "    BasisLibrary(n_features=1, feature_names=[\"x\"])\n",
    "    .add_constant()\n",
    "    .add_linear()\n",
    "    .add_polynomials(max_degree=3)\n",
    ")\n",
    "\n",
    "model = SymbolicRegressor(\n",
    "    basis_library=library,\n",
    "    max_terms=3,\n",
    "    strategy=\"greedy_forward\",\n",
    ")\n",
    "model.fit(X_jax, y_jax)\n",
    "\n",
    "print(f\"Discovered: {model.expression_}\")\n",
    "print(f\"Estimated noise std: {model.sigma_:.4f} (true: 0.5)\")\n",
    "\n",
    "# Coefficient confidence intervals\n",
    "print(\"\\n95% coefficient intervals:\")\n",
    "for name, (est, lo, hi, se) in model.coefficient_intervals().items():\n",
    "    print(f\"  {name}: {est:.4f} [{lo:.4f}, {hi:.4f}]\")\n",
    "\n",
    "# Prediction intervals on new data\n",
    "X_new = jnp.array([[1.0], [2.5], [4.0]])\n",
    "y_pred, pred_lo, pred_hi = model.predict_interval(X_new)\n",
    "y_pred_c, conf_lo, conf_hi = model.confidence_band(X_new)\n",
    "\n",
    "print(\"\\nPrediction vs confidence intervals:\")\n",
    "for i in range(3):\n",
    "    x = float(X_new[i, 0])\n",
    "    print(\n",
    "        f\"  x={x:.1f}: pred=[{float(pred_lo[i]):.2f}, {float(pred_hi[i]):.2f}], \"\n",
    "        f\"conf=[{float(conf_lo[i]):.2f}, {float(conf_hi[i]):.2f}]\"\n",
    "    )\n",
    "\n",
    "# Conformal prediction (distribution-free)\n",
    "y_pred_conf, lo_conf, hi_conf = model.predict_conformal(X_new, alpha=0.05)\n",
    "print(\"\\nConformal 95% intervals (Jackknife+):\")\n",
    "for i in range(3):\n",
    "    x = float(X_new[i, 0])\n",
    "    print(f\"  x={x:.1f}: [{float(lo_conf[i]):.2f}, {float(hi_conf[i]):.2f}]\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}