{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e568ba78",
   "metadata": {},
   "source": [
    "# Basic Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a0a741",
   "metadata": {},
   "source": [
    "Basic Usage Example for JAXSR.\n",
    "\n",
    "Demonstrates the core functionality of JAXSR for discovering\n",
    "algebraic expressions from data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41d13b80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-07T12:00:57.064425Z",
     "iopub.status.busy": "2026-02-07T12:00:57.064299Z",
     "iopub.status.idle": "2026-02-07T12:00:58.384877Z",
     "shell.execute_reply": "2026-02-07T12:00:58.384444Z"
    }
   },
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "from jaxsr import BasisLibrary, SymbolicRegressor, fit_symbolic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e622c3b",
   "metadata": {},
   "source": [
    "## Discover a polynomial expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96b804bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-07T12:00:58.387126Z",
     "iopub.status.busy": "2026-02-07T12:00:58.386926Z",
     "iopub.status.idle": "2026-02-07T12:01:00.462838Z",
     "shell.execute_reply": "2026-02-07T12:01:00.462442Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "True model: y = 2.5*x0 + 1.2*x0*x1 - 0.8*x1^2\n",
      "Data: 200 samples, 2 features, noise std=0.1\n",
      "\n",
      "Basis library: 8 candidate functions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Discovered expression:\n",
      "  y = - 0.7996*x1^2 + 2.502*x0 + 1.198*x0*x1 - 0.002767*x0^2\n",
      "\n",
      "Metrics:\n",
      "  R² score: 0.999827\n",
      "  MSE: 0.009535\n",
      "  BIC: -341.78\n",
      "  Complexity: 7\n"
     ]
    }
   ],
   "source": [
    "# Generate synthetic data: y = 2.5*x0 + 1.2*x0*x1 - 0.8*x1^2 + noise\n",
    "np.random.seed(42)\n",
    "n_samples = 200\n",
    "X = np.random.randn(n_samples, 2) * 2\n",
    "y = 2.5 * X[:, 0] + 1.2 * X[:, 0] * X[:, 1] - 0.8 * X[:, 1] ** 2\n",
    "y += np.random.randn(n_samples) * 0.1\n",
    "\n",
    "X_jax = jnp.array(X)\n",
    "y_jax = jnp.array(y)\n",
    "\n",
    "print(\"\\nTrue model: y = 2.5*x0 + 1.2*x0*x1 - 0.8*x1^2\")\n",
    "print(f\"Data: {n_samples} samples, 2 features, noise std=0.1\")\n",
    "\n",
    "# Build basis library\n",
    "library = (\n",
    "    BasisLibrary(n_features=2, feature_names=[\"x0\", \"x1\"])\n",
    "    .add_constant()\n",
    "    .add_linear()\n",
    "    .add_polynomials(max_degree=3)\n",
    "    .add_interactions(max_order=2)\n",
    ")\n",
    "\n",
    "print(f\"\\nBasis library: {len(library)} candidate functions\")\n",
    "\n",
    "# Fit model\n",
    "model = SymbolicRegressor(\n",
    "    basis_library=library,\n",
    "    max_terms=5,\n",
    "    strategy=\"greedy_forward\",\n",
    "    information_criterion=\"bic\",\n",
    ")\n",
    "model.fit(X_jax, y_jax)\n",
    "\n",
    "# Results\n",
    "print(\"\\nDiscovered expression:\")\n",
    "print(f\"  {model.expression_}\")\n",
    "print(\"\\nMetrics:\")\n",
    "print(f\"  R² score: {model.score(X_jax, y_jax):.6f}\")\n",
    "print(f\"  MSE: {model.metrics_['mse']:.6f}\")\n",
    "print(f\"  BIC: {model.metrics_['bic']:.2f}\")\n",
    "print(f\"  Complexity: {model.complexity_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff173d50",
   "metadata": {},
   "source": [
    "## Discover an expression with transcendental functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8157b48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-07T12:01:00.464735Z",
     "iopub.status.busy": "2026-02-07T12:01:00.464568Z",
     "iopub.status.idle": "2026-02-07T12:01:01.813397Z",
     "shell.execute_reply": "2026-02-07T12:01:01.812959Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "True model: y = exp(-0.5*x) + log(x+1)\n",
      "Data: 150 samples, 1 feature\n",
      "\n",
      "Basis library: 7 candidate functions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Discovered expression:\n",
      "  y = 0.9152 + 0.3777*sqrt(x) + 0.002365*exp(x)\n",
      "  R² score: 0.983003\n"
     ]
    }
   ],
   "source": [
    "# Generate data: y = exp(-0.5*x) + log(x+1)\n",
    "np.random.seed(42)\n",
    "n_samples = 150\n",
    "X = np.random.uniform(0.1, 3.0, (n_samples, 1))\n",
    "y = np.exp(-0.5 * X[:, 0]) + np.log(X[:, 0] + 1)\n",
    "y += np.random.randn(n_samples) * 0.02\n",
    "\n",
    "X_jax = jnp.array(X)\n",
    "y_jax = jnp.array(y)\n",
    "\n",
    "print(\"\\nTrue model: y = exp(-0.5*x) + log(x+1)\")\n",
    "print(f\"Data: {n_samples} samples, 1 feature\")\n",
    "\n",
    "# Build library with transcendental functions\n",
    "library = (\n",
    "    BasisLibrary(n_features=1, feature_names=[\"x\"])\n",
    "    .add_constant()\n",
    "    .add_linear()\n",
    "    .add_polynomials(max_degree=3)\n",
    "    .add_transcendental([\"log\", \"exp\", \"sqrt\"])\n",
    ")\n",
    "\n",
    "print(f\"\\nBasis library: {len(library)} candidate functions\")\n",
    "\n",
    "model = SymbolicRegressor(\n",
    "    basis_library=library,\n",
    "    max_terms=6,\n",
    "    strategy=\"greedy_forward\",\n",
    ")\n",
    "model.fit(X_jax, y_jax)\n",
    "\n",
    "print(\"\\nDiscovered expression:\")\n",
    "print(f\"  {model.expression_}\")\n",
    "print(f\"  R² score: {model.score(X_jax, y_jax):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14c517b",
   "metadata": {},
   "source": [
    "## Use the fit_symbolic convenience function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1238a5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-07T12:01:01.815373Z",
     "iopub.status.busy": "2026-02-07T12:01:01.815180Z",
     "iopub.status.idle": "2026-02-07T12:01:03.269669Z",
     "shell.execute_reply": "2026-02-07T12:01:03.269277Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "True model: y = 3*a^2 - 2*b + 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jkitchin/Dropbox/projects/jaxsr/src/jaxsr/regressor.py:1220: UserWarning: Removing 4 basis functions with non-finite values\n",
      "  return model.fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Discovered: y = 3*a^2 - 2.008*b + 1.004\n",
      "R² = 0.9998\n"
     ]
    }
   ],
   "source": [
    "# Generate data\n",
    "np.random.seed(42)\n",
    "X = np.random.randn(100, 2)\n",
    "y = 3.0 * X[:, 0] ** 2 - 2.0 * X[:, 1] + 1.0\n",
    "y += np.random.randn(100) * 0.05\n",
    "\n",
    "print(\"\\nTrue model: y = 3*a^2 - 2*b + 1\")\n",
    "\n",
    "# Quick fit\n",
    "model = fit_symbolic(\n",
    "    jnp.array(X),\n",
    "    jnp.array(y),\n",
    "    feature_names=[\"a\", \"b\"],\n",
    "    max_terms=5,\n",
    "    max_poly_degree=3,\n",
    ")\n",
    "\n",
    "print(f\"\\nDiscovered: {model.expression_}\")\n",
    "print(f\"R² = {model.score(jnp.array(X), jnp.array(y)):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecaf3ce",
   "metadata": {},
   "source": [
    "## Explore the Pareto front of complexity vs accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8c48198",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-07T12:01:03.271567Z",
     "iopub.status.busy": "2026-02-07T12:01:03.271413Z",
     "iopub.status.idle": "2026-02-07T12:01:03.595224Z",
     "shell.execute_reply": "2026-02-07T12:01:03.594791Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pareto Front (Complexity vs MSE):\n",
      "  Complexity  2 | MSE 4.223643\n",
      "    y = 1.63*y^2\n",
      "\n",
      "  Complexity  3 | MSE 0.214977\n",
      "    y = 1.496*y^2 + 2.091*x\n",
      "\n",
      "  Complexity  5 | MSE 0.008936\n",
      "    y = 1.497*y^2 + 2.002*x - 0.5041*x*y\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate data\n",
    "np.random.seed(42)\n",
    "X = np.random.randn(150, 2)\n",
    "y = 2.0 * X[:, 0] + 1.5 * X[:, 1] ** 2 - 0.5 * X[:, 0] * X[:, 1]\n",
    "y += np.random.randn(150) * 0.1\n",
    "\n",
    "X_jax = jnp.array(X)\n",
    "y_jax = jnp.array(y)\n",
    "\n",
    "library = (\n",
    "    BasisLibrary(n_features=2, feature_names=[\"x\", \"y\"])\n",
    "    .add_constant()\n",
    "    .add_linear()\n",
    "    .add_polynomials(max_degree=3)\n",
    "    .add_interactions(max_order=2)\n",
    ")\n",
    "\n",
    "model = SymbolicRegressor(\n",
    "    basis_library=library,\n",
    "    max_terms=6,\n",
    "    strategy=\"greedy_forward\",\n",
    ")\n",
    "model.fit(X_jax, y_jax)\n",
    "\n",
    "print(\"\\nPareto Front (Complexity vs MSE):\")\n",
    "for result in model.pareto_front_:\n",
    "    print(f\"  Complexity {result.complexity:2d} | MSE {result.mse:.6f}\")\n",
    "    print(f\"    {result.expression()}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3078fe",
   "metadata": {},
   "source": [
    "## Demonstrate model export capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71cdb3fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-07T12:01:03.597168Z",
     "iopub.status.busy": "2026-02-07T12:01:03.597006Z",
     "iopub.status.idle": "2026-02-07T12:01:04.032143Z",
     "shell.execute_reply": "2026-02-07T12:01:04.031666Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Expression: y = 2*a + b^2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SymPy: 2.0*a + 1.00000011920929*b**2.0\n",
      "LaTeX: 2.0 a + 1.00000011920929 b^{2.0}\n",
      "\n",
      "Pure NumPy predictions:\n",
      "  X = [[1.0, 2.0], [3.0, 4.0]]\n",
      "  y_pred = [6.000000476837158, 22.000001907348633]\n"
     ]
    }
   ],
   "source": [
    "# Generate and fit\n",
    "np.random.seed(42)\n",
    "X = np.random.randn(100, 2)\n",
    "y = 2.0 * X[:, 0] + X[:, 1] ** 2\n",
    "\n",
    "model = fit_symbolic(\n",
    "    jnp.array(X),\n",
    "    jnp.array(y),\n",
    "    feature_names=[\"a\", \"b\"],\n",
    "    max_terms=4,\n",
    ")\n",
    "\n",
    "# Human-readable expression\n",
    "print(f\"\\nExpression: {model.expression_}\")\n",
    "\n",
    "# SymPy export\n",
    "try:\n",
    "    sympy_expr = model.to_sympy()\n",
    "    print(f\"SymPy: {sympy_expr}\")\n",
    "\n",
    "    # LaTeX\n",
    "    latex = model.to_latex()\n",
    "    print(f\"LaTeX: {latex}\")\n",
    "except ImportError:\n",
    "    print(\"(SymPy not available for symbolic export)\")\n",
    "\n",
    "# Pure Python callable\n",
    "predict_fn = model.to_callable()\n",
    "X_test = np.array([[1.0, 2.0], [3.0, 4.0]])\n",
    "y_pred = predict_fn(X_test)\n",
    "print(\"\\nPure NumPy predictions:\")\n",
    "print(f\"  X = {X_test.tolist()}\")\n",
    "print(f\"  y_pred = {y_pred.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d959a125",
   "metadata": {},
   "source": [
    "## Demonstrate uncertainty quantification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d83cc8e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-07T12:01:04.034646Z",
     "iopub.status.busy": "2026-02-07T12:01:04.034435Z",
     "iopub.status.idle": "2026-02-07T12:01:05.267077Z",
     "shell.execute_reply": "2026-02-07T12:01:05.266670Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "True model: y = 2*x + 1 (noise std = 0.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discovered: y = 1.954*x + 1.108\n",
      "Estimated noise std: 0.4536 (true: 0.5)\n",
      "\n",
      "95% coefficient intervals:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  x: 1.9540 [1.8932, 2.0148]\n",
      "  1: 1.1075 [0.9386, 1.2765]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction vs confidence intervals:\n",
      "  x=1.0: pred=[2.15, 3.97], conf=[2.94, 3.18]\n",
      "  x=2.5: pred=[5.09, 6.90], conf=[5.90, 6.08]\n",
      "  x=4.0: pred=[8.01, 9.83], conf=[8.79, 9.06]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Conformal 95% intervals (Jackknife+):\n",
      "  x=1.0: [2.07, 4.05]\n",
      "  x=2.5: [5.00, 6.98]\n",
      "  x=4.0: [7.94, 9.91]\n"
     ]
    }
   ],
   "source": [
    "# Generate data with known noise level\n",
    "np.random.seed(42)\n",
    "n_samples = 100\n",
    "X = np.random.uniform(0, 5, (n_samples, 1))\n",
    "y_true = 2.0 * X[:, 0] + 1.0\n",
    "y = y_true + np.random.randn(n_samples) * 0.5\n",
    "\n",
    "X_jax = jnp.array(X)\n",
    "y_jax = jnp.array(y)\n",
    "\n",
    "print(\"\\nTrue model: y = 2*x + 1 (noise std = 0.5)\")\n",
    "\n",
    "# Fit model\n",
    "library = (\n",
    "    BasisLibrary(n_features=1, feature_names=[\"x\"])\n",
    "    .add_constant()\n",
    "    .add_linear()\n",
    "    .add_polynomials(max_degree=3)\n",
    ")\n",
    "\n",
    "model = SymbolicRegressor(\n",
    "    basis_library=library,\n",
    "    max_terms=3,\n",
    "    strategy=\"greedy_forward\",\n",
    ")\n",
    "model.fit(X_jax, y_jax)\n",
    "\n",
    "print(f\"Discovered: {model.expression_}\")\n",
    "print(f\"Estimated noise std: {model.sigma_:.4f} (true: 0.5)\")\n",
    "\n",
    "# Coefficient confidence intervals\n",
    "print(\"\\n95% coefficient intervals:\")\n",
    "for name, (est, lo, hi, se) in model.coefficient_intervals().items():\n",
    "    print(f\"  {name}: {est:.4f} [{lo:.4f}, {hi:.4f}]\")\n",
    "\n",
    "# Prediction intervals on new data\n",
    "X_new = jnp.array([[1.0], [2.5], [4.0]])\n",
    "y_pred, pred_lo, pred_hi = model.predict_interval(X_new)\n",
    "y_pred_c, conf_lo, conf_hi = model.confidence_band(X_new)\n",
    "\n",
    "print(\"\\nPrediction vs confidence intervals:\")\n",
    "for i in range(3):\n",
    "    x = float(X_new[i, 0])\n",
    "    print(\n",
    "        f\"  x={x:.1f}: pred=[{float(pred_lo[i]):.2f}, {float(pred_hi[i]):.2f}], \"\n",
    "        f\"conf=[{float(conf_lo[i]):.2f}, {float(conf_hi[i]):.2f}]\"\n",
    "    )\n",
    "\n",
    "# Conformal prediction (distribution-free)\n",
    "y_pred_conf, lo_conf, hi_conf = model.predict_conformal(X_new, alpha=0.05)\n",
    "print(\"\\nConformal 95% intervals (Jackknife+):\")\n",
    "for i in range(3):\n",
    "    x = float(X_new[i, 0])\n",
    "    print(f\"  x={x:.1f}: [{float(lo_conf[i]):.2f}, {float(hi_conf[i]):.2f}]\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
